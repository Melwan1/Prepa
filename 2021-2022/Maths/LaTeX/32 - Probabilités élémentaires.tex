\documentclass[12pt,a4paper]{report}

\input{00 - preambule}

\begin{document}

\newcommand{\p}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}

\section*{Introduction}

La théorie des probabilités a pour objet la modélisation mathématique du hasard, des expériences aléatoires. \\
Une expérience aléatoire est une expérience qui a plusieurs résultats possibles (on dit aussi issues) qu'on ne peut prévoir avec certitude, mais qui présente (c'est 
crucial) une régularité statistique sur le long terme. Il est postulé ici notamment la possibilité de répéter l'expérience un grand nombre de fois, dans des 
conditions identiques (dans l'idéal), de façon indépendante (les différentes répétitions n'ont aucune influence les unes sur les autres). \\
On prend un exemple. Une des expériences aléatoires les plus simples est le jeu de pile ou face : lorsqu'on jette une pièce de monnaie et qu'on regarde quel côté de 
la pièce apparaît, il n'y a que deux issues possibles (pile ou face), et on ne peut prévoir avec certitude quel côté de la pièce apparaît avant de l'avoir lancée. Si 
on jette la même pièce un grand nombre de fois, il semble que la proportion du nombre de piles parmi le nombre total se rapproche d'un nombre fixe (0.5 en général si 
la pièce est équilibrée, un autre nombre sinon), ce qui conduit à définir un nombre qui mesure le degré de vraisemblance d'apparition de pile pour un lancer donné 
(c'est ce qu'on appellera la probabilité d'apparition de pile). Le fait que le hasard fonctionne ainsi résulte de l'expérience (vous pourriez chacun jeter 500 fois 
une pièce de monnaie et consigner combien de fois vous avez obtenu pile dans la série de lancers ; si on fait la moyenne des 47 proportions obtenues, on ne sera pas 
très loin de 0.5...) \\
La modélisation mathématique des phénomènes aléatoires comporte trois ingrédients principaux : 
\begin{enumerate}
	\item L'espace d'états, ou univers, noté traditionnellement $\Omega$ ; c'est l'ensemble de toutes les issues possibles de notre expérience aléatoire. Prenons quelques exemples : 
	\begin{itemize}
		\item Un jeu de pile ou face aura pour univers l'ensemble $\Omega = \{P,F\}$, ou $\Omega = \{0,1\}$. L'expérience aléatoire qui consiste à jeter $n$ fois une 
		pièce, et à collecter les résultats des $n$ lancers se modélise en prenant pour univers $\Omega = \{P,F\}^n$. Un résultat est une suite $\omega = (\omega_1,\cdots,\omega_n)$ d'éléments de $\{P,F\}$.
		\item On modélise l'expérience aléatoire qui consiste à lancer deux dés en prenant pour univers l'ensemble $\Omega = \{1,2,3,4,5,6\}^2$.
		\item L'expérience aléatoire qui consiste à tirer avec remise $n$ boules d'une urne qui contient $N$ boules distinctes (numérotées de $1$ à $N$) aura pour 
		univers $\Omega = \{1,\cdots,N\}$
		\item L'expérience aléatoire qui consiste à tirer en succession et sans remise $n$ boules d'une urne qui contient $N$ boules distinctes (numérotées de $1$ à 
		$N$) aura pour univers l'ensemble des $n$-arrangements d'éléments de $\{1,\cdots,N\}$
		\item L'expérience aléatoire qui consiste à tirer une poignée de $n$ boules dans une urne qui en contient $N$ numérotées de $1$ à $N$ aura pour univers 
		naturel l'ensemble des parties à $n$ éléments de l'ensemble $\{1,\cdots,N\}$ 
		\item L'expérience aléatoire consistant à mesurer la durée de vie d'une ampoule électrique a pour univers $\Omega = \R_+$
	\end{itemize}
	
	Cette année, on s'occupera uniquement du cas où l'ensemble $\Omega$ est fini (cela simplifie beaucoup la théorie mais permet quand même d'en introduire tout le vocabulaire et pas mal d'aspects).
	
	\item Les événements. Un événement est une propriété, vérifiée ou non une fois l'expérience aléatoire réalisée. Par exemple, si on jette deux dés, on peut 
	s'intéresser à l'événement : "la somme des résultats obtenus est un nombre inférieur ou égal à 4". Mathématiquement, un événement sera modélisé par l'ensemble des 
	issues qui le réalisent, c'est donc une partie de l'univers $\Omega$. L'événement de notre exemple est ainsi modélisé par l'ensemble 
	\begin{center}
	$\{(1,1),(1,2),(2,1),(1,3),(3,1),(2,2)\}$
	\end{center}
	Lorsque $\Omega$ est fini, l'ensemble des événements est l'ensemble $P(\Omega)$ des parties de $\Omega$. Il y a un langage propre à la théorie :
	\begin{itemize}
		\item Les événements $\{\omega\}$ (singletons) s'appellent les événements élémentaires.
		\item Si $A$ est un événement, et si l'expérience aléatoire a donné l'issue $\omega$, la traduction de "l'événement $A$ est réalisé" est : $\omega \in A$. 
		\item L'univers $\Omega$ s'appellent l'événement certain, $\varnothing$ est l'événement impossible.
		\item Si $A$ et $B$ sont deux événements, $A \cup B$ est l'événement "$A$ ou $B$", $A \cap B$ est l'événement "$A$ et $B$", et le complémentaire de $A$, noté $\overline{A}$ ou $A^c$ s'appelle l'événement contraire de $A$. Les événements $A$ et $B$ sont incompatibles lorsque $A \cap B = \varnothing$. On dit que $A$ implique $B$ lorsque $A \subset B$.
	\end{itemize}
	
	\item La probabilité $\p$ : à chaque événement $A$ est attaché un nombre $\p(A)$, élément de $[0,1]$, qui mesure le degré de vraisemblance de $A$ (ce nombre est 
	d'autant plus proche de $1$ que les chances que $A$ se produise sont élevées). \\
	
	Reprenons notre approche fréquentielle : répétons l'expérience aléatoire $n$ fois, on note $f_n(A)$ la fréquence de réalisation de l'événement $A$ (c'est le 
	quotient du nombre de fois où $A$ s'est produit par $n$, nombre total de réalisations de l'expérience). On prend alors :
	\begin{center}
	$\p(A) = \underset{n \to +\infty}{\lim} f_n(A)$
	\end{center}
	en postulant l'existence de cette limite. D'après les propriétés des fréquences, on aura alors $\p(\Omega) = 1$ et $\p(A \cup B) = \p(A)+\p(B)$ lorsque $A$ et $B$ 
	sont disjoints. C'est ce qui va nous conduire à la définition rigoureuse d'une probabilité. Le postulat de régularité statistique ne sert qu'à justifier les 
	définitions mathématiques qui vont suivre. Un des aspects très satisfaisant de la théorie est qu'en retour on peut démontrer cette régularité statistique (ce sont 
	les résultats connus sous le nom de loi des grands nombres).
\end{enumerate}

Il y a aussi un quatrième ingrédient, dont nous reparlerons plus tard : les variables aléatoires.

\newpage

\section{Probabilités sur un univers fini}

\subsection{Espaces probabilisés}

\begin{definition}{Probabilité}{}
Soit $\Omega$ un ensemble (univers) fini. On appelle \Strong{probabilité} sur $\Omega$ toute application $\p$ de $P(\Omega)$ dans $[0,1]$ telle que :
\begin{enumerate}
\item $\p(\Omega) = 1$
\item Si $A$ et $B$ sont deux événements incompatibles, $\p(A \cup B) = \p(A) + p(B)$ (additivité)
\end{enumerate}
\end{definition}

\begin{definition}{Espace probabilisé}{}
On appelle \Strong{espace probabilisé fini} tout couple $(\Omega,\p)$ où $\Omega$ est un univers fini et $\p$ une probabilité sur $\Omega$.
\end{definition}

\begin{remarque}{}
Il y a un vocabulaire attaché à la probabilité, un peu artificiel quand on a affaire à des ensembles finis, mais qu'on donne quand même. \\
Soit $(\Omega,\p)$ un espace probabilisé fini. \\
On dit qu'un événement $A$ est \Strong{négligeable} lorsque $\p(A) = 0$ et \Strong{quasi certain} si $\p(A) = 1$. \\
Une propriété sur $\Omega$ est vraie \Strong{presque sûrement} si l'ensemble des points $\omega$ où la propriété est fausse est négligeable. \\

On peut se poser la question de l'existence dans le cas fini d'événements négligeables autres que l'événement impossible. En effet, la modélisation conduit en général
à attribuer à chaque événement élémentaire une probabilité strictement positive, mais rien n'empêche d'ajouter artificiellement des issues de probabilité nulle. Dans 
le cas d'ensembles infinis (non dénombrables), la situation est bien différente. Par exemple, si on modélise un jeu de pile ou face infini (c'est un idéal 
mathématique, évidemment), on est amené à considérer l'ensemble non dénombrable $\Omega = \{0,1\}^\N$ (ensemble des suites infinies d'éléments de $\{0,1\}$). On 
démontre qu'on peut munir $\Omega$ d'une probabilité $\p$ conforme à notre intuition (par exemple, la probabilité d'obtenir "pile" à un lancer donné est de $\dfrac{1}{2}$, 
la probabilité que les $n$ premiers lancers aient des valeurs données est $\dfrac{1}{2^n}$). Alors on montre facilement que la probabilité de chaque événement 
élémentaire est nulle, de même que celle d'obtenir "pile" tous les trois lancers. Il y a bien dans ce cas des événements négligeables qui ne sont pas l'événement 
impossible.

\end{remarque}

\pagebreak

Donnons tout de suite les principales propriétés des probabilités :

\begin{proposition}{Propriétés principales des probabilités}{}

Soit $(\Omega,\p)$ un espace probabilisé fini, $A$ et $B$ deux événements.
\begin{enumerate}
	\item $\p(\varnothing) = 0$
	\item $\p(\overline{A}) = 1- \p(A)$.
	\item Si $A \subset B$, alors $\p(A) \le \p(B)$ (on dit que $\p$ est \strong{croissante}). \\
	Plus précisément, on a $\p(B \setminus A) = \p(B) - \p(A)$ lorsque $A \subset B$.
	\item $\p(A \cup B) = \p(A) + \p(B) - \p(A \cap B)$
	\item Si $A_1,\cdots,A_n$ sont des événements deux à deux incompatibles, alors (additivité finie) :
	\begin{center}
	$\displaystyle \p \left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n \p(A_k)$
	\end{center}
	
	\item Si $A_1,\cdots,A_n$ sont des événements quelconques, alors (inégalité de Boole) :
	\begin{center}
	$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) \le \sum_{k=1}^N \P(A_k)$
	\end{center}
\end{enumerate}

\end{proposition}

\begin{demo}{}
Soient $A$ et $B$ deux événements tels que $A \subset B$. Alors $B$ est réunion disjointe de $A$ et de $B \setminus A$, donc 
\begin{center}
$\p(B) = \p(A \cup (B \setminus A)) = \p(A)+\underbrace{\p(B \setminus A)}_{\ge 0}$,
\end{center}

et ceci donne les trois premières assertions (prendre $A = B = \varnothing$ pour la première, $B = \Omega$ pour la deuxième). \\
À présent, si $A$ et $B$ sont deux événements quelconques, on observe que $A \cup B$ est réunion disjointe de $A$ et de $B \setminus (A \cap B)$ \footnotemark, d'où
\begin{center}
$\p(A \cup B) = \p(A) + \p(B \setminus (A \cap B)) = \p(A) + \p(B) - \p(A \cap B)$
\end{center}

Les deux dernières assertions se prouvent facilement par récurrence.
\end{demo}

\footnotetext{Faire un dessin pour le voir.}

\begin{definition}{Système complet d'événements}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A_1,\cdots,A_n$ des événements. \\
On dit que $(A_1,\cdots,A_n)$ est un \Strong{système complet d'événements} si les $A_i$ sont deux à deux incompatibles et si la réunion des $A_i$ est $\Omega$.
\end{definition}

\begin{remarque}{}
Si $(A_1,\cdots,A_n)$ est un système complet d'événements, on a par additivité finie :
\begin{center}
$1 = \p(\Omega) = \displaystyle \sum_{k=1}^n \p(A_k)$
\end{center}
\end{remarque}

\begin{exemple}{}
Pour tout événement $A$ d'un espace probabilisé fini $(\Omega,\p)$, $(A, \overline{A})$ est un système complet d'événements.\\ 
De même, $({\omega})_{\omega \in \Omega}$ est aussi un système complet d'événements.
\end{exemple}

\begin{proposition}{}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $(A_1,\cdots,A_n)$ un système complet d'événements. Alors, pour tout événement $B$, on a :
\begin{center}
$\p(B) = \displaystyle \sum_{k=1}^n \p(B \cap A_k)$
\end{center}
\end{proposition}

\begin{demo}{}
Soit $B$ un événement. On a :
\begin{center}
$B = B \cap \Omega = B \cap \displaystyle \bigcup_{k=1}^n A_k = \bigcup_{k=1}^n (B \cap A_k)$
\end{center}

et les divers ensembles $B \cap A_1,\cdots,B\cap A_n$ sont deux à deux disjoints, d'où le résultat par additivité finie.
\end{demo}

\begin{exemple}[Exercice 1]{}
La proposition précédente reste vraie si on suppose seulement que les $A_i$ sont deux à deux incompatibles et que leur réunion est un événement quasi-certain.
\end{exemple}

\begin{exemple}[Exercice 2]{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A$ et $B$ deux événements tels que $\p(A) = \dfrac{3}{4}$ et $\p(B) = \dfrac{1}{3}$. \\
Prouver que $\dfrac{1}{12} \le \p(A \cap B) \le \dfrac{1}{3}$. \\

Preuve : on a déjà $\p(A \cap B) = \p(A) + \p(B) - \underbrace{\p(A \cup B)}_{\text{positif et inférieur ou égal à 1}} \ge \dfrac{3}{4}+\dfrac{1}{3}-1 = \dfrac{1}{12}$. \\

De plus, l'événement $A \cap B$ implique l'événement $B$, donc $\p(A \cap B) \le \p(B) = \dfrac{1}{3}$.

\end{exemple}

\begin{exemple}[Exercice 3]{}
Soit $\Omega,\p)$ un espace probabilisé fini, $A_1,\cdots,A_n$ des événements (avec $n \ge 2$). \\
Prouver que
\begin{center}
$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) \ge \sum_{k=1}^n \p(A_k) - \sum_{1 \le k < \ell \le n} \p(A_k \cap A_\ell)$
\end{center}
\end{exemple}

\begin{exemple}[Exercice 4]{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A,B,C$ des événements. Prouver que
\begin{center}
$\p(A \cup B \cup C) = \p(A) + \p(B) + \p(C) - \p(A \cap B) - \p(B \cap C) - \p(A \cap C) + \p(A \cap B \cap C)$
\end{center}
\end{exemple}

Le résultat de l'exercice suivant n'est pas officiellement au programme, mais il est utile, c'est conseillé de le retenir : 

\begin{exemple}[Exercice 5]{Formule de Poincaré}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A_1,\cdots,A_n$ des événements (avec $n \ge 2$). \\
Prouver que :
\begin{center}
$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n (-1)^{k-1} \left(\sum_{1 \le i_1 < \cdots < i_k \le n} \p(A_{i_1} \cap \cdots A_{i_n})\right)$
\end{center}

La somme intérieure porte sur les suites strictement croissantes de $k$ entiers de $\{1,\cdots,n\}$. L'ensemble de ces suites est en bijection avec l'ensemble des 
parties à $k$ éléments de $\{1,\cdots,n\}$ (il n'y a qu'une seule façon de classer par ordre croissant les éléments d'une partie de $\{1,\cdots,n\}$). La somme 
intérieure est donc la somme des probabilités de toutes les intersections possibles de $k$ ensembles parmi $A_1,\cdots,A_n$, elle comporte $\begin{pmatrix} n \\ k\end{pmatrix}$ termes. 
Le premier terme de la somme (obtenu pour $k = 1$) est la somme des probabilités des ensembles $A_1,\cdots,A_n$, affectée d'un signe $+$. Il y a ensuite alternance de 
signes entre deux termes consécutifs. Le dernier terme est $(-1)^{n-1}\p(A_1 \cap \cdots \cap A_n)$. \\

On a l'écriture alternative suivante (en notant, pour $k \in \{1,\cdots,n\}$, $\mathcal{P}_k(n)$ l'ensemble des parties à $k$ éléments de l'ensemble $\{1,\cdots,n\}$) :
\begin{center}
$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n (-1)^{k-1} \left(\sum_{I \in \mathcal{P}_k(n)} \p\left(\bigcap_{\ell \in I}\right)\right)$
\end{center}

Indice : par récurrence.

\end{exemple}

\begin{remarque}[Petite histoire]{}
Donnons-nous dans un premier temps un ensemble fini $\Omega$.
\begin{itemize}
	\item Soit $\p$ une probabilité sur $\Omega$. Si $A$ est un événement, alors $A$ est réunion disjointe des singletons formés d'un élément de $A$, on a donc, par 
	additivité finie : 
	\begin{center}
	$\p(A) = \displaystyle \sum_{\omega \in A} \p(\{\omega\})$
	\end{center}
	
	On voit donc que $\p$ est entièrement déterminée par sa valeur sur les événements élémentaires. \\
	
	De plus, pour chaque élément $\omega$ de $\Omega$, on a $\p(\{\omega\}) \ge 0$ et $1 = \p(\Omega) = \displaystyle \sum_{\omega \in \Omega} \p(\{\omega\})$.
	
	\item Réciproquement, si on se donne une famille $(p_\omega)_{\omega \in \Omega}$ de nombres réels positifs ou nuls, indexée par $\Omega$, de somme 1, et si on pose, pour $A \in \mathcal{P}(\Omega)$,
	\begin{center}
	$\p(A) = \displaystyle \sum_{\omega \in A} p_\omega$
	\end{center}
	on vérifie sans difficulté aucune qu'on définit bien de cette manière une probabilité sur l'ensemble fini $\Omega$ (exercice).
\end{itemize}
\end{remarque}

Résumons :

\begin{theoreme}{}{}
Se donner une probabilité sur l'ensemble fini $\Omega$ revient à se donner une famille $(p_\omega)_{\omega \in \Omega}$ de nombres réels positifs ou nuls de somme 1. \\
Plus précisément, si on dispose d'une telle famille, il y a une et une seule probabilité $\p$ sur $\Omega$ telle que $\p(\{\omega\}) = p_\omega$ pour tout élément $\omega$ de $\Omega$.
\end{theoreme}

Examinons à présent une situation courante, celle où toutes les issues possibles ont même probabilité : 

\begin{theoreme}{Probabilité uniforme}{}
Soit $\Omega$ un ensemble fini. Il existe une et une seule probabilité $\p$ sur $\Omega$, appelée \Strong{probabilité uniforme}, qui a la même valeur sur tous les 
singletons. \\
On a, pour tout élément $\omega$ de $\Omega$, et pour tout événement $A$ :
\begin{center}
$\p(\{\omega\}) = \dfrac{1}{\text{Card } \Omega}$ et $\p(A) = \dfrac{\text{Card } A}{\text{Card } \Omega}$
\end{center}
\end{theoreme}

\begin{demo}{}
Si $\p$ existe, on doit avoir, en notant $p$ la valeur commune de $\p$ sur les singletons,
\begin{center}
$1 = \p(\Omega) = \displaystyle \sum_{\omega \in \Omega} \p(\{\omega\}) = \sum_{\omega \in \Omega} p = p \text{Card } \Omega$
\end{center}
Donc $p = \dfrac{1}{\text{Card } \Omega}$. \\

Si maintenant on pose, pour $\omega \in \Omega$, $p_\omega = \dfrac{1}{\text{Card } \Omega}$, on a là une famille de réels positifs de somme 1, il existe donc une 
unique probabilité $\p$ sur $\Omega$ telle que
\begin{center}
$\forall \omega \in \Omega, \p(\{\omega\}) = \dfrac{1}{\text{Card} \Omega}$
\end{center}
et on a bien, pour tout événement $A$,
\begin{center}
$\p(A) = \displaystyle \sum_{\omega \in A} \p(\{\omega\}) = \sum_{\omega \in A} \dfrac{1}{\text{Card } \Omega} = \dfrac{\text{Card } A}{\text{Card } \Omega}$
\end{center}
\end{demo}

\begin{remarque}{}
Chaque fois qu'un énoncé fait référence à des tirages ou des choix "au hasard", à des dés "équitables, ou équilibrés, ou non truqués", à des pièces "équilibrées, ou 
non truquées" (pour les jeux de pile ou face), à des boules ou des jetons "indiscernables" (pour des énoncés à bases de tirages dans des urnes), c'est qu'on a affaire 
à une situation d'équiprobabilité, et on munira donc l'univers correspondant de la probabilité uniforme. \\

Le terme "tirage au hasard" n'est pas très bien choisi, le hasard n'est pas toujours synonyme d'équiprobabilité. Par exemple, si l'expérience aléatoire consiste à 
jeter deux dés et à noter la somme des deux résultats obtenus (l'univers est donc l'ensemble des entiers compris entre 2 et 12), il est clair que qu'on a pas affaire 
à une situation d'équiprobabilité, bien que le "hasard" soit toujours à l'œuvre.
\end{remarque}

\begin{remarque}{}
Dans le cas de la probabilité uniforme, la formule $\p(A) = \dfrac{\text{Card } A}{\text{Card } \Omega}$ se lit quelquefois "nombre de cas favorables sur nombre de 
cas possibles" (un cas favorable est une issue qui réalise l'événement $A$). Dans cette situation (très souvent rencontrée), calculer une probabilité, c'est faire du 
dénombrement.
\end{remarque}

\begin{remarque}{}
Un grand nombre d'énoncés aiment à contextualiser la situation : on parle de lancer de dés, de jets de pièces, de tirages dans des urnes. M. Sellès est enclin à 
éviter ce genre d'énoncé, et rester dans le domaine mathématique pur et dur, mais il faut quand même vous préparer à les affronter. Dans ce cas là, c'est à vous de 
préciser quel univers vous adoptez pour modéliser la situation, et aussi quelle probabilité vous considérez sur cet univers. Revenons sur les modèles à base de 
tirages dans des urnes, pour les trois cas les plus simples :
\begin{enumerate}
	\item Si on effectue $n$ tirages avec remise (chaque tirage a lieu en succession, et on remet la boule tirée dans l'urne après chaque tirage) dans une urne qui 
	contient $N$ boules, on prend en général comme univers $\Omega = \{1,\cdots,N\}^n$ et on considère que chaque tirage est équiprobable. Dans ce cas, 
	$\text{Card } \Omega = N^n$. On peut très bien simuler ainsi un jeu de pile ou face (considérer une urne qui contient deux boules).
	\item Si on effectue $n$ tirages successifs sans remise (chaque tirage a lieu en succession, et on garde la boule tirée dans l'urne après chaque tirage) dans une 
	urne qui contient $N$ boules, on prend comme univers $\Omega$ l'ensemble des $n$-uplets d'entiers distincts de $\{1,\cdots,N\}$ (on imagine qu'on a numéroté les 
	$N$ boules), c'est-à-dire les $n$-arrangements de l'ensemble $\{1,\cdots,N\}$, et dans ce cas, $\text{Card}  \Omega = N(N-1) \cdots (N-n+1)$
	\item Si on effectue des tirages simultanés de $n$ boules (on tire des poignées de $n$ boules) dans une urne qui en contient $N$, l'univers $\Omega$ adéquat est 
	en général l'ensemble des parties à $n$ éléments de l'ensemble des $N$ boules, et on a dans ce cas $\text{Card } \Omega = \begin{pmatrix} N \\ n \end{pmatrix}$.
\end{enumerate}
Notons que les fameuses urnes peuvent aussi servir à modéliser des situations non équiprobables (même si les tirages le sont). C'est souvent le cas lorsque l'ensemble 
des boules est divisé en une ou plusieurs sous-populations (caractérisées, en général, par la couleur). Si on vous dit par exemple qu'une urne contient 7 boules, dont 
4 vertes et 3 rouges, et que l'expérience aléatoire consiste à tirer une boule, et à noter sa couleur, on peut prendre comme univers $\Omega = \{V,R\}$ avec $\p(V) = \dfrac{4}{7}$ et $\p(R) = \dfrac{3}{7}$, on a ainsi modélisé un jeu de pile ou face non équitable.
\end{remarque}

\begin{exemple}[Exercice 6]{}
Une urne contient 6 boules rouges, 5 boules vertes et 3 boules bleues.
\begin{enumerate}
	\item On tire simultanément trois boules de l'urne. Quelle est la probabilité d'avoir un tirage unicolore ? Quelle est la probabilité d'avoir un tirage 
	tricolore ? Quelle est la probabilité d'avoir un tirage bicolore ?
	
	$\rightarrow$ Pour avoir un tirage unicolore, il faut soit tirer trois rouges, soit trois bleues, soit trois vertes. La probabilité de tirer trois rouges vaut $\dfrac{6}{14}\dfrac{5}{13}\dfrac{4}{12} = \dfrac{5}{91}$, la probabilité de tirer trois bleues est $\dfrac{3}{14} \dfrac{2}{13} \dfrac{1}{12} = \dfrac{1}{364}$ et celle de tirer trois vertes vaut $\dfrac{5}{14}\dfrac{4}{13}\dfrac{3}{12} = \dfrac{5}{182}$. Donc la probabilité d'obtenir un tirage unicolore vaut $\dfrac{5}{91} + \dfrac{5}{182} + \dfrac{1}{364} = \dfrac{31}{364}$. \\
	
	Tirage tricolore : la première boule n'importe pas, elle est de la couleur qu'on veut.
	Si elle est rouge, alors il faut tirer une verte et une bleue. Si la deuxième est bleue, la troisième doit être verte. probabilité de tout ceci : $\dfrac{6}
{14}\dfrac{3}{13}\dfrac{5}{12} = \dfrac{5}{364}$. \\
	Si la deuxième est verte, la troisième est bleue. Probabilité : $\dfrac{5}{364}$ \\
	Probabilité avec la première rouge : $\dfrac{5}{182}$. \\
	De même, la probabilité d'obtenir un tirage tricolore avec la première boule bleue vaut $\dfrac{5}{182}$, et $\dfrac{5}{182}$ avec la première boule verte. \\
	Donc la probabilité d'obtenir un tirage tricolore est (événements incompatibles) : $\dfrac{15}{182}$.
	
	Les événements "obtenir un tirage tricolore ou unicolore" et "obtenir un tirage bicolore" sont un système complet d'événements, donc la probabilité d'obtenir un 
	tirage bicolore vaut $1-\dfrac{31}{364}-{15}{182} = \dfrac{303}{364}$
	
	\item On effectue maintenant trois tirages successifs avec remise. Répondre aux mêmes questions que dans le premier cas.
	
	\item On effectue trois tirages successifs sans remise. Répondre aux mêmes questions que dans le premier cas. \\
	Quelle est la probabilité que la première boule bleue tirée le soit au troisième tirage ? 
	
\end{enumerate}

\end{exemple}

\subsection{Conditionnement et indépendance}

Il s'agit là d'une notion centrale en probabilités. Essayons de justifier de façon intuitive les définitions qui vont suivre. Considérons une expérience aléatoire, et 
un événement $A$ liée à cette expérience aléatoire. Supposons qu'on sache qu'un certain événement $B$ est réalisé. On a une information supplémentaire, qui va a 
priori modifier les chances de réalisation de $A$, puisqu'elle modifie l'univers qu'on considère. Si on considère encore une fois l'approche par les fréquences, on 
imagine qu'on répète l'expérience aléatoire $n$ fois. On va cette fois compter combien de fois $A$ s'est réalisé lorsque $B$ s'est réalisé. Sur les $n$ répétitions, 
$B$ s'est réalisé $nf_n(B)$ fois, et lorsque $B$ a eu lieu, $A$ s'est aussi réalisé autant de fois que $A \cap B$, c'est-à-dire $nf_n(A \cap B)$ fois. La fréquence de 
réalisation de $A$ parmi les fois où $B$ s'est réalisé est donc :
\begin{center}
$\dfrac{nf_n(A \cap B)}{nf_n(B)} = \dfrac{f_n(A\cap B)}{f_n(B)}$
\end{center}
quantité qui devrait tendre vers $\dfrac{\p(A \cap B)}{\p(B)}$, c'est ce qu'on va appeler la \Strong{probabilité conditionnelle de $A$ sachant $B$}. On dira que $A$ 
est \Strong{indépendant} de $B$ si la réalisation de $B$ n'influe pas sur les chances de réalisation de $A$, c'est-à-dire si la probabilité conditionnelle de $A$ 
sachant $B$ est égale à la probabilité de $A$, ce qui donne $\p(A) = \dfrac{\p(A \cap B)}{\p(B)}$, ou encore (c'est une condition symétrique en $A$ et $B$) si :
\begin{center}
$\p(A \cap B) = \p(A) \p(B)$
\end{center}

\subsubsection{Indépendance}

\begin{definition}{Indépendance}{}
Soit $(\Omega,\p)$ un espace probabilisé fini.
\begin{enumerate}
	\item Soient $A$ et $B$ deux événements. On dit que $A$ et $B$ sont \Strong{indépendants} lorsque 
	\begin{center}
	$\p(A \cap B) = \p(A) \p(B)$
	\end{center}
	\item (Généralisation) Soient $A_1,\cdots,A_n$ des événements. On dit que $A_1,\cdots,A_n$ sont \Strong{indépendants} (on dit aussi \strong{mutuellement 
	indépendants}) lorsque : \\
	pour toute partie non vide $I$ de $\{1,\cdots,n\}$, on a :
	\begin{center}
	$\displaystyle \p\left(\bigcap_{\ell \in I} A_\ell\right) = \prod_{\ell \in I} \p(A_\ell)$
	\end{center}
\end{enumerate}
\end{definition}

\begin{remarque}{}
La notion d'indépendance peut ne pas être très intuitive. Pour montrer que deux événements sont indépendants, il faut faire un calcul de probabilité, l'argument ne peut pas être "on voit bien que", notamment dans les énoncés contextualisés. Le mot "indépendant" a ici une signification mathématique précise. Prenons quelques exemples qui vous convaincront, on l'espère :
\begin{enumerate}
	\item On joue à pile ou face, on effectue deux lancers consécutifs, on note $p$ la probabilité d'apparition de pile à chaque lancer (c'est un réel compris entre 0 et 1). On modélise cette expérience aléatoire par l'univers $\Omega = \{P,F\}^2$, muni de la probabilité $\p$ définie par :
	\begin{center}
		$\P(\{(P,P)\}) = p^2, \p(\{(F,F)\}) = (1-p)^2, \p(\{(F,P)\}) = \p(\{(P,F)\}) = p(1-p)$.
	\end{center}
	
	Considérons $A = \{(P,F),(F,P)\}$ et $B = \{(P,P),(P,F)\}$. \\
	On a tout de suite $\p(A) = 2p(1-p)$ et $\p(B) = p^2+p(1-p) = p$, tandis que $\p(A \cap B) = p(1-p)$. \\
	
	On voit donc que $A$ et $B$ sont indépendants si et seulement si
	\begin{center}
	$p(1-p) = 2p^2(1-p)$
	\end{center}
	ce qui ne laisse que les solutions $p = 0$, $p = 1$ et $p = \dfrac{1}{2}$. \\
	En particulier, dans le cas d'un jeu équilibré ($p = 1/2$), les événements $A$ et $B$ sont indépendants, alors qu'il ne le sont pour aucune valeur non triviale de $p$ (et pourtant, ce sont les mêmes événements). 
	
	\item On considère l'ensemble des familles de trois enfants (du point de vue de la distribution des sexes). En notant $f$ pour fille, $g$ pour garçon, on a 8 possibilités pour les familles de trois enfants (on les range du plus vieux au plus jeune), qu'on va considérer comme étant équiprobables (ce n'est peut-être pas là la bonne modélisation). Autrement dit, on considère l'ensemble $\Omega = \{f,g\}^3$, muni de la probabilité uniforme. Un triplet tel que $(f,g,g)$ indique que le premier enfant est une fille, suivie de deux garçons. Chaque triplet a la probabilité $1/8$. \\
	
	Soit $A$ l'événement "la famille est mixte" (c'est-à-dire présente des enfants des deux sexes), et $B$ l'événement "la famille a au plus un garçon". \\
	Le calcul des probabilités donne $\p(A) = \dfrac{3}{4}$, $\p(B) = \dfrac{1}{2}$, et $\p(A \cap B) = \dfrac{3}{8}$, donc $A$ et $B$ sont indépendants. \\
	
	Si on considère "les mêmes" événements pour des familles de $4$ enfants, ils ne sont plus indépendants (exercice). Ils ne le sont pas non plus pour les familles de deux enfants.
\end{enumerate}
\end{remarque}

\begin{remarque}{}
Dans le cas de $n$ événements, avec $n \ge 3$, il y a en fait $2^n-n-1$ conditions à vérifier (la relation à vérifier étant triviale pour les parties $I$ de $\{1,\cdots,n\}$ de cardinal 1). Par exemple lorsque $n = 3$, les événements $A$, $B$ et $C$ sont indépendants si et seulement si :
\begin{center}
$\p(A \cap B) = \p(A) \p(B)$, $\p(A \cap C) = \p(A) \p(C)$ et $\p(B \cap C) = \p(B) \p(C)$ \\
$\p(A \cap B \cap C) = \p(A)\p(B) \p(C)$
\end{center}
\end{remarque}

L'indépendance de trois événements implique donc l'indépendance deux à deux. On pourrait penser que la réciproque est vraie, mais ce n'est pas le cas. De même, la deuxième condition n'implique pas l'indépendance deux à deux. On vous renvoie aux deux exemples suivants.

\begin{exemple}{}
Considérons $\Omega = \{a,b,c,d\}$, muni de la probabilité uniforme. Soient $A = \{a,d\}$, $B = \{b,d\}$ et $C = \{c,d\}$. Alors les événements $A,B,C$ sont deux à deux indépendants, mais on a $\p(A\cap B \cap C) \ne \p(A)\p(B)\p(C)$.
\end{exemple}

\begin{exemple}{}
Soit $\Omega = \{1,\cdots,8\}$, muni de la probabilité uniforme. On prend $A = B = \{1,5,6,7\}$, et $C = \{1,2,3,4\}$. Alors $\p(A \cap B \cap C) = \p(A) \p(B) \p(C)$, mais $A,B$ et $C$ ne sont pas deux à deux indépendants.
\end{exemple}

\begin{exemple}[Exercice 7]{}
Soit $n$ un entier, $n \ge 2$. On modélise un jeu de pile ou face équitable avec $n$ lancers par l'univers $\{0,1\}^n$, muni de la probabilité uniforme. Pour tout entier $i$ compris entre $1$ et $n$, on note $A_i$ l'événement "le $i$-ème lancer à donné pile" (dans notre modèle, $A_i$ est l'ensemble des $\omega = (\omega_1,\cdots,\omega_n)$ tels que $\omega_i = 1$).
\begin{enumerate}
	\item Pour $1 \le i < j \le n$, prouver que $A_i$ et $A_j$ sont indépendants.
	\item Prouver que les événements $(A_1,\cdots,A_n)$ sont indépendants.
	\item Pour $1 \le k \le n$, soit $B_k$ l'événement "on a obtenu $k$ piles exactement parmi les $n$ lancers". Quelle est la probabilité de $B_k$ ?
\end{enumerate}
\end{exemple}

\begin{remarque}{}
L'indépendance d'événements $A_1,\cdots,A_n$ ne dépend évidemment pas de leur ordre d'énumération. \\
Par ailleurs, si $A_1,\cdots,A_n$ sont indépendants, il est tout aussi clair que $A_1,\cdots,A_k$ le sont aussi, pour tout entier $k$ compris entre $1$ et $n$.
\end{remarque}

\begin{proposition}{}{}
Soient $A$ et $B$ deux événements indépendance de l'espace probabilisé $(\Omega, \p)$. \\
Alors les événements $\overline{A}$ et $B$ sont aussi indépendants, de même que $A$ et $\overline{B}$ et $\overline{A}$ et $\overline{B}$.
\end{proposition}

\begin{demo}{}
Il suffit évidemment de montrer que $\overline{A}$ et $B$ sont indépendants. On remarque que
\begin{center}
$B = B \cap \Omega = B \cap (A \cup \overline{A}) = (B \cap A) \cup (B \cap \overline{A})$,
\end{center}
et les événements $B \cap A$ et $B \cap \overline{A}$ sont incompatibles. On a donc 
\begin{center}
$\p(B \cap \overline{A}) = \p(B) - \p(B \cap A) = \p(B)-\p(B)\p(A) = \p(B)(1-\p(A)) = \p(B)\p(\overline{A})$. 
\end{center}
\end{demo}

La proposition précédente se généralise ainsi : 
\begin{proposition}{}{}
Soient $A_1,\cdots,A_n$ des événements indépendants de l'espace probabilisé $(\Omega,\p)$. Alors il en est de même des événements $B_1,\cdots,B_n$ où $B_i$ est $A_i$ ou $\overline{A_i}$ pour tout entier $i$ compris entre $1$ et $n$.
\end{proposition}

\begin{demo}{}
Il suffit en fait de voir que les événements $\overline{A_1},A_2,\cdots,A_n$ sont indépendants (voyez-vous pourquoi ?), et pour ceci, il suffit de prouver que si $k$ est un entier compris entre $2$ et $n$, alors
\begin{center}
$\p(\overline{A_1} \cap A_2 \cap \cdots \cap A_k) = \p(\overline{A_1}) \p(A_2) \cdots \p(A_k)$.
\end{center}

Or c'est facile : soit $k$ un entier compris entre $2$ et $n$. On remarque que $A_1$ et $C = A_2 \cap \cdots \cap A_k$ sont indépendants car 
\begin{center}
$\p(A_1 \cap C) = \displaystyle \p\left(\bigcap_{i=1}^k A_i\right) = \prod_{i=1}^k \p(A_i) = \p(A_1)\p(C)$.
\end{center}
par indépendance de $A_1,\cdots,A_n$.

D'après la proposition précédente, $\overline{A}$ et $C$ sont indépendants, ce qui entraîne le résultat.
\end{demo}

\begin{proposition}{}{}
Soient $A_1,\cdots,A_n$ des événements indépendants de l'espace probabilisé $(\Omega,\p)$, et $p$ un entier compris entre $1$ et $n-1$. Alors 
\begin{enumerate}
	\item Les événements $A_1 \cap \cdots \cap A_p$ et $A_{p+1}\cap \cdots A_n$ sont indépendants.
	\item Les événements $A_1 \cup \cdots \cup A_p$ et $A_{p+1}\cup \cdots A_n$ sont indépendants.
	\item Les événements $A_1 \cap \cdots \cap A_p$ et $A_{p+1}\cup \cdots A_n$ sont indépendants.
\end{enumerate}
\end{proposition}

\begin{demo}{}
Montrons la première assertion. \\
Soit $A = A_1 \cap \cdots \cap A_p$ et $B = A_{p+1} \cap \cdots \cap A_n$. \\

Alors $A \cap B = A_1 \cap \cdots \cap A_n$ et par indépendance de $A_1,\cdots,A_n$, on a 
\begin{center}
$\p(A \cap B) = \p(A_1 \cap \cdots \cap A_n) = \displaystyle \prod_{k=1}^n \p(A_k)$
\end{center}

Or, toujours par indépendance de $A_1,\cdots,A_n$, on a 
\begin{center}
$\p(A) = \displaystyle \prod_{k=1}^p \p(A_k)$ et $\p(B) = \displaystyle \prod_{k=p+1}^n \p(A_k)$,
\end{center}
on en déduit bien que
\begin{center}
$\p(A \cap B) = \p(A) \p(B)$.
\end{center}

Pour la deuxième assertion, remarquons que les événements $\overline{A_1}, \cdots, \overline{A_n}$ sont indépendants d'après la proposition précédente. D'après le premier cas, les événements $A = \displaystyle \bigcap_{k=1}^p \overline{A_k}$ et $B = \displaystyle \bigcap_{k=p+1}^n \overline{A_k}$ sont indépendants. Or on a 
\begin{center}
$A =\displaystyle \overline{\bigcup_{k=1}^p A_k}$ et $B = \displaystyle \overline{\bigcup_{k=p+1}^n A_k}$.
\end{center}

Comme $\overline{A}$ et $\overline{B}$ sont indépendants, on a le résultat. \\

Pour la troisième assertion, remarquons que les événements $A_1,\cdots,A_p, \overline{A_{p+1}}, \cdots, \overline{A_n}$ sont indépendants. On en déduit que $A = \bigcap_{k=1}^p A_k$ et $B = \bigcap_{k=1}^p \overline{A_k} = \overline{\bigcup_{k=1}^p A_k}$ sont indépendants d'après le premier cas. On sait alors que $A$ et $\overline{B}$ sont aussi indépendants. 

\end{demo}

\paragraph{Modélisation d'une succession d'épreuves indépendantes}

Imaginons pour commencer qu'on ait modélisé deux expériences aléatoires $\mathcal{E}_1$ et $\mathcal{E}_2$ avec les espaces probabilisés finis $(\Omega_1,\p_1)$ et $(\Omega_2,\p_2)$. On aimerait modéliser la succession des deux expériences, de façon indépendante. Un résultat lié à cette succession est un couple $(\omega_1,\omega_2)$ avec $\omega_1 \in \Omega_1$ et $\omega_2 \in \Omega_2$. \\
On va donc prendre pour univers l'ensemble $\Omega = \Omega_1 \times \Omega_2$. \\
Reste à définir une probabilité $\p$ sur $\Omega$ qui traduise l'indépendance. \\

Ce qu'on veut, c'est que si $A_1$ est un événement lié à l'expérience $\mathcal{E}_1$, $A_2$ un événement lié à $\mathcal{E}_2$, alors $A_1$ et $A_2$ sont indépendants dans la succession de $\mathcal{E}_1$ et $\mathcal{E}_2$. Une petite difficulté se présente ici, puisque si $A_1$ est une partie de $\Omega_1$, ce n'est pas une partie de $\Omega$, on va la remplacer par $A_1 \times \Omega_2$ (il semble logique de considérer que $A_1$ et $A_1 \times \Omega_2$ représentent le même événement). Dans cette optique, on va imposer que $\p(A_1 \times \Omega_2) = \p_1(A_1)$. On imposera de même $\p(\Omega_1 \times A_2) = \p_2(A_2)$ pour toute partie $A_2$ de $\Omega_2$. \\

On veut donc définir une probabilité $\p$ sur $\Omega$ de telle sorte que pour toutes parties $A_1$ et $A_2$ de $\Omega_1$ et $\Omega_2$, on ait d'une part
\begin{center}
$\p(A_1 \times \Omega_2) = \p_1(A_1), \p(\Omega_1 \times A_2) = \p_2(A_2)$,
\end{center}
et d'autre part (puisqu'on veut l'indépendance de $A_1 \times \Omega_2$ et $\Omega_1 \times A_2$), 
\begin{center}
$\p((A_1 \times \Omega_2) \cap (\Omega_1 \times A_2)) = \p(A_1 \times \Omega_2) \p(\Omega_1 \times A_2)$.
\end{center}
or, il est clair que $(A_1 \times \Omega_2) \cap (\Omega_1 \times A_2) = A_1 \times A_2$, on est ainsi conduit à poser, pour $A_1$ partie de $\Omega_1$ et $A_2$ partie de $\Omega_2$, 
\begin{center}
$\p(A_1 \times A_2) = \p_1(A_1) \p_2(A_2)$,
\end{center}
et, en particulier, pour tout $\omega = (\omega_1,\omega_2)\in \Omega$,
\begin{center}
$\p(\{\omega\}) = \p_1(\{\omega_1\}) \p_2(\{\omega_2\}) \underset{\text{def}}{=} p_\omega$
\end{center}

Or il est clair que les nombres $p_\omega$ sont des réels positifs, et de plus
\begin{center}
$\displaystyle \sum_{\omega \in \Omega} p_\omega = \sum_{(\omega_1,\omega_2) \in \Omega_1 \times \Omega_2}  \p_1(\{\omega_1\}) \p_2(\{\omega_2\}) = \underbrace{\left(\sum_{\omega_1 \in \Omega_1}\p_1(\{\omega_1\})\right)}_{=1}\underbrace{\left(\sum_{\omega_2 \in \Omega_2} \p_2(\{\omega_2\})\right)}_{=1} = 1$
\end{center}
Il existe donc bien une probabilité $\p$ sur $\Omega$ telle que $\p(\{\omega\}) = p_\omega$ pour $\omega \in \Omega$, et $\p$ a bien les propriétés attendues. La probabilité $\p$ ainsi définie s'appelle la \Strong{probabilité produit}. \\

On généralise sans problèmes à la modélisation d'une succession indépendante de $n$ expériences aléatoires, modélisées par les espaces probabilisés finis $(\Omega_i,\p_i)$ ($1 \le i \le n$) : il suffit de considérer l'univers $\Omega = \prod_{i=1}^n \Omega_i$ (produit cartésien des ensembles $\Omega_1, \cdots,\Omega_n$), muni du l'unique probabilité $\p$ telle que, quels que soient les éléments $A_i \subset \Omega_i$ ($1 \le i \le n$) : 
\begin{center}
$\p(A_1 \times \cdots \times A_n) = \p_1(A_1) \cdots \p_n(A_n)$.
\end{center}

On peut en particulier modéliser une succession finie de $n$ expériences aléatoires identiques et indépendantes (on parle d'épreuves répétées). Supposons avoir modélisé une expérience aléatoire par un espace probabilisé fini $(\Omega,\p)$. Alors une suite de $n$ épreuves sera modélisée par l'espace probabilisé $(\Omega^n, \mathbb{Q})$, où la probabilité $\mathbb{Q}$ est telle que : quels que soient les événements $A_1, \cdots, A_n$, 
\begin{center}
$\mathbb{Q}(A_1 \times \cdots \times A_n) = \p(A_1) \cdots \p(A_n)$
\end{center}

En particulier, pour tout élément $\omega = (\omega_1,\cdots,\omega_n) \in \Omega^n$, 
\begin{center}
$\mathbb{Q}(\{\omega\}) = \p(\{\omega_1\}) \cdots \p(\{\omega_n\})$
\end{center}

C'est ainsi qu'on modélise un jeu de pile ou face à $n$ lancers. L'expérience que l'on répète (un lancer) est modélisée en général par $\Omega = \{0,1\}$ (où, par exemple, $1$ représente "pile" et $0$ représente "face"), muni de la probabilité $\p$ définie par $\p(\{1\}) = p \in [0,1]$ et $\p(\{0\}) = 1-p = q$. \\
La suite des $n$ lancers indépendante est alors modélisée par l'univers $\{0,1\}^n$, muni de la probabilité $\mathbb{Q}$ définie par
\begin{center}
$\forall \omega = (\omega_1,\cdots,\omega_n) \in \{0,1\}^n, \mathbb{Q}(\{\omega\}) = \displaystyle \prod_{k=1}^n \p(\{\omega_k\}) = p^\ell q^{n-\ell}$
\end{center}
où $\ell$ est le nombre de composantes de $\omega$ qui valent $1$. \\

Dans le cas d'un jeu équitable ($p = q = \dfrac{1}{2}$), on retrouve l'univers $\{0,1\}^n$ muni de la probabilité uniforme. \\

On appellera plus généralement \Strong{épreuve de Bernoulli} toute expérience aléatoire ayant deux issues possibles, baptisées en général "succès" et "échec". Il est clair qu'on peut modéliser une telle expérience par l'univers $\Omega = \{0,1\}$, où $1$ représente (par exemple) le succès, et $0$ l'échec. Une suite de $n$ épreuves de Bernoulli porte le nom de \Strong{schéma de Bernoulli}, et peut se modéliser comme le jeu de pile ou face.

\subsubsection{Probabilité conditionnelle}

\begin{definition}{Probabilité conditionnelle}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A$ et $B$ deux événements, avec $\p(B) \ne 0$. \\
On appelle \Strong{probabilité conditionnelle} de $A$ sachant $B$, et on note $\p_B(A)$ (ou parfois $\p(A \mid B)$), le nombre 
\begin{center}
$\p_B(A) = \dfrac{\p(A \cap B)}{\p(B)}$
\end{center}
\end{definition}

On a donc
\begin{center}
$\p(A \cap B) = \p(B) \p_B(A)$.
\end{center}

Voici un exemple d'utilisation. 

\begin{exemple}{}
On considère des familles de deux enfants (on supposera que chaque enfant a une chance sur deux d'être une fille). \\
Quelle est la probabilité de les deux enfants soient des filles sachant que l'aîné est une fille ? \\
Quelle est la probabilité que les deux enfants soient des filles sachant qu'un des deux est une fille ? \\

On adopte la modélisation suivante, suggérée par l'énoncé : $\Omega = \{ff,fg,gf,gg\}$, muni de la probabilité uniforme (le sexe de l'aîné est codé par la première lettre). \\
L'événement "les deux enfants sont des filles" est $A = \{ff\}$. L'événement "l'aîné est une fille" est $B = \{fg,ff\}$. L'événement "un des deux enfants est une fille" est $C = \{ff,fg,gf\}$. La première question est de trouver $\p_B(A)$, et la réponse est $1/2$. LA deuxième question demande $\p_C(A)$,et la réponse est $1/3$.
\end{exemple}

\begin{remarque}[Avertissement]{}
Dans bien des énoncés, ce sont des probabilités conditionnelles qui sont données, et c'est à vous d'interpréter correctement l'énoncé pour les donner (on revient donc à une définition plus ou moins floue de cette quantité). Prenons un exemple : \\

Céline et Olivier jouent aux fléchettes. Céline a trois chances sur dix de toucher la cible, Olivier a sept chances sur dix de toucher la cible. Céline tire deux fois plus qu'Olivier (pour compenser son manque d'adresse). Quelle est la probabilité que la cible soit touchée lors d'un tir ? \\

Comment modéliser cette expérience aléatoire ? Une issue est un couple (tireur,résultat). On prend pour $\Omega$ l'ensemble $\{(C,T),(C,R),(O,T),(O,R)\}$ ($C$ code Céline, $O$ Olivier, $T$ touché et $R$ raté). \\
L'événement "Céline tire" est $A = \{(C,T),(C,R)\}$. L'événement "Olivier tire" est précisément $\overline{A}$. \\
Il reste à trouver une probabilité $\p$ sur $\Omega$ compatible avec l'énoncé. \\

L'énoncé nous dit que $\p(A) = 2\p(\overline{A})$, et comme $\p(A) + \p(\overline{A}) = 1$, on a $\p(A) = \dfrac{2}{3}$ et $\p(\overline{A}) = \dfrac{1}{3}$. \\

Notons $B$ l'événement "la cible est touchée", on a $B = \{(C,T),(O,T)\}$. L'énoncé nous dit (c'est là qu'on interprète les probabilités conditionnelles) que la probabilité que la cible soit touchée sachant que Céline tire est $0.3$ c'est à dire que $\p_A(B) = 0.3$. On en déduit
\begin{center}
$\p(\{(C,T)\}) = \p(A \cap B) = \p(A) \p_A(B) = \dfrac{2}{3} \dfrac{3}{10}$.
\end{center}

Vous remarquerez qu'on a utilisé la définition de la probabilité conditionnelle pour calculer la probabilité de l'intersection. On aura de même $\p_{\overline{A}}(B) = 0.7$, et 
\begin{center}
$\p(\{(O,T)\}) = \p(\overline{A} \cap B) = \p(\overline{A}) \p_{\overline{A}}(B) = \dfrac{1}{3}\dfrac{7}{10}$,
\end{center}
ce qui donne
\begin{center}
$\p(B) = \dfrac{6}{30}+\dfrac{7}{30} = \dfrac{13}{30}$.
\end{center}

On peut déterminer entièrement la probabilité $\p$ de la même manière. \\

Moralité : dans cet exercice, on a trouvé les probabilités conditionnelles avec notre bon sens, et on en a déduit les autres probabilités.
\end{remarque}

La proposition suivante découle immédiatement de la définition :

\begin{proposition}{Caractérisation de l'indépendance}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A$ et $B$ deux événements, avec $\p(B) \ne 0$. \\
Alors $A$ et $B$ sont indépendants si, et seulement si, $\p_B(A) = \p(A)$.
\end{proposition}

La probabilité conditionnelle porte bien son nom, c'est en effet une probabilité :

\begin{proposition}{}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, et $B$ un événement de probabilité non nulle. Alors $\p_B$ est une probabilité sur $\Omega$.
\end{proposition}

\begin{demo}{}
Tout d'abord, si $A$ est un événement, alors $A \cap B \subset B$, donc $\p(A \cap B) \le \p(B)$,et ceci assure que $\p_B(A)$ est un réel de l'intervalle $[0,1]$. \\

On a $B \cap \omega = B$, donc $\p_B(\Omega) = 1$. \\
Enfin, si $A_1$ et $A_2$ sont des événements incompatibles, on a $B \cap (A_1 \cup A_2) = (B \cap A_1) \cup (B \cap A_2)$, et les événements $B \cap A_1$ et $B \cap A_2$ sont incompatibles, on a donc
\begin{center}
$\p(B \cap (A_1 \cup A_2)) = \p(B \cap A_1) + \p(B \cap A_2)$
\end{center}
et on obtient, en divisant par $\p(B)$, $\p_B(A_1 \cup A_2) = \p_B(A_1) + \p_B(A_2)$. 

\end{demo}

La probabilité conditionnelle hérite donc de toutes les propriétés d'une probabilité, on aura par exemple $\p_B(\overline{A}) = 1- \p_B(A)$, et $\p_B(A_1) \le \p_B(A_2)$ si $A_1 \subset A_2$... \\

Les trois théorèmes qui suivent sont fondamentaux :

\begin{theoreme}{Formule des probabilités totales}{}
Soit $(\Omega, \p)$ un espace probabilisé fini, $(A_1,\cdots,A_n)$ un système complet d'événements tel que $\p(A_i) \ne 0$ pour tout $i$. Alors, pour tout événement $B$,
\begin{center}
$\p(B) = \displaystyle \sum_{i=1}^n \p_{A_i}(B) \p(A_i)$
\end{center}
En particulier, si $A$ est un événement tel que $\p(A) \in ]0,1[$, alors pour tout événement $B$, 
\begin{center}
$\p(B) = \p_A(B)\p(A) + \p_{\overline{A}}(B)\p(\overline{A})$
\end{center}
\end{theoreme}

\begin{demo}{}
Si $B$ est un événement, on a vu que $\p(B) = \sum_{i=1}^n \p(B \cap A_i)$. Et pour $i$ élément de $\{1,\cdots,n\}$, on a, puisque $\p(A_i) \ne 0, \p(B \cap A_i) = \p_{A_i}(B)\p(\overline{A})$.
\end{demo}

Avant de donner un exemple d'utilisation, on va donner le deuxième théorème, ils vont souvent ensemble.

\begin{lemme}{}{}
Soient $A$ et $B$ deux événements de probabilité non nulle d'un espace probabilisé $(\Omega, \p)$. On a
\begin{center}
$\p_B(A) = \dfrac{\p(A) \p_A(B)}{\p(B)}$
\end{center}
\end{lemme}

\begin{demo}{}
On a en effet, dans ce cas :
\begin{center}
$\p_B(A)\p_B = \p(A \cap B) = \p_A(B) \p(A)$
\end{center}
\end{demo}

\begin{remarque}{}
Cette formule anodine porte le nom de \Strong{formule de probabilité des causes}. Supposons que l'événement $A$ se produise avant l'événement $B$. On peut alors, connaissant $\p_A(B)$ (la probabilité que $B$ survienne si la cause $A$ s'est produite), trouver $\p_B(A)$ (en quelque sorte, la probabilité que ce soit la cause $A$ qui ait produit $B$). Mais ce n'est là qu'une interprétation. La formule s'applique sans aucun lien de temporalité, ou de causalité entre les événements $A$ et $B$.
\end{remarque}

\begin{theoreme}{Formule de Bayes}{}
Soit $(\Omega, \p)$ un espace probabilisé fini, $(A_1,\cdots,A_n)$ un système complet d'événements tels que $\p(A_i) \ne 0$ pour tout $i$. Alors, pour tout événement $B$ tel que $\p(B) \ne 0$, on a 
\begin{center}
$\p_B(A_i) = \dfrac{\p(A_i)\p_{A_i}(B)}{\p(B)} = \dfrac{\p(A_i) \p_{A_i}(B)}{\displaystyle \sum_{j=1}^n \p_{A_j}(B) \p(A_j)}$
\end{center}

En particulier, si $A$ est un événement de probabilité $p \in ]0,1[$, alors pour tout événement $B$ de probabilité non nulle :
\begin{center}
$\p_B(A) = \dfrac{\p_A(B) \p(A)}{\p_A(B) \p(A) + \p_{\overline{A}}(B) \p(\overline{A})}$.
\end{center}
\end{theoreme}

\begin{demo}{}
c'est immédiat en combinant le lemme et le théorème précédent.
\end{demo}

\begin{exemple}{}
Revenons sur nos deux tireurs (Céline et Olivier)\footnotemark. Retrouvons (sans tout modéliser) la probabilité que la cible soit touchée. Notons $A_1$ l'événement "Céline tire", $A_2$ l'événement "Olivier tire"\footnotemark, et $T$ l'événement "la cible est touchée". L'énoncé nous dit que :
\begin{center}
$\p(A_1) = \dfrac{2}{3}, \p(A_2) = \dfrac{1}{2}$, $\p_{A_1}(T) = 0.3$ et $\p_{A_2}(T) = 0.7$.
\end{center}

\footnotetext{N'oublions pas aussi que Olivier vise beaucoup mieux que Céline... Serait-ce là toute la puissance du Grand Sensei ?}

\footnotetext{Et c'est vrai que c'est un événement, tout le monde admire le Grand Sensei...}

En utilisant la formule des probabilités totales avec le système complet d'événement $(A_1,A_2)$, on a :
\begin{center}
$\p(T) = \p(A_1)\p_{A_1}(T) + \p(A_2) \p_{A_2}(T) = \dfrac{2}{3} \dfrac{3}{10} + \dfrac{1}{3} \dfrac{7}{10} = \dfrac{13}{30}$.
\end{center}

Supposons maintenant qu'un tir a lieu, et que la cible soit touchée. Quelle est la probabilité que ce soit Céline qui ait tiré ? \\
On cherche maintenant $\p_T(A_1)$, et c'est là qu'on utilise la formule de Bayes.
\begin{center}
$\p_T(A_1) = \dfrac{\p_{A_1}(T)\p(A_1)}{\p(T)} = \dfrac{\frac{3}{10}\frac{2}{3}}{\frac{13}{30}} = \dfrac{6}{13}$.
\end{center}
\end{exemple}

\pagebreak

\begin{theoreme}{Formules des probabilités composées}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A_1, \cdots, A_n$ des événements (avec $n \ge 2$). On suppose que $\p(A_1 \cap \cdots \cap A_{n-1})\ne 0$. On a alors
\begin{center}
$\p(A_1 \cap \cdots \cap A_{n-1} \cap A_n) = \p(A_1)\p(A_2 \mid A_1)\p(A_3 \mid A_1 \cap A_2)\cdots \p(A_n \mid A_1 \cap \cdots A_{n-1})$
\end{center}
\end{theoreme}

\begin{demo}{}
Produit téléscopique.
\end{demo}

\begin{exemple}{}
Une urne contient $5$ boules rouges et $7$ boules vertes. On effectue $3$ tirages sans remise. Quelle est la probabilité d'obtenir $3$ boules rouges ? \\

On ne va pas modéliser cette expérience, ce qui est donné ici sont les probabilités conditionnelles. Au passage, pourriez-vous proposer une modélisation de cette expérience aléatoire ? \\

Notons $R_i$ l'événement : le $i$-ème tirage donne une boule rouge. \\
On a, selon l'énoncé, $\p(R_1) = \dfrac{5}{12}$. \\

$\p(R_2 \mid R_1) = \dfrac{4}{11}$ (puisque : si on a tiré une boule rouge au premier tirage, il reste dans l'urne $11$ boules, dont $4$ rouges), et de même $\p(R_3 \mid R_1 \cap R_2) = \dfrac{3}{10}$. \\

On cherche $\p(R_1 \cap R_2 \cap R_3)$. La formule des probabilités composées donne donc
\begin{center}
$\p(R_1 \cap R_2 \cap R_3) = \dfrac{5}{12} \dfrac{4}{11} \dfrac{3}{10}$.
\end{center}

Quelle est la probabilité qu'une boule rouge apparaisse pour la première fois au deuxième tirage ? Au troisième ?
\end{exemple}

\begin{exemple}[Exercice - Urne de Pólya]{}
Une urne contient initialement $r \ge 1$ boules rouges, et $b \ge 1$ boules blanches. On effectue des tirages successifs d'une boule, en remettant après chaque tirage la boule tirée avec en plus $c \ge 1$ boules de la même couleur. Pour tout entier $n \ge 1$, on note $R_n$ (resp. $B_n$) l'événement : "la $n$-ème boule tirée est rouge (resp. blanche)"
\begin{enumerate}
	\item Quelle est la probabilité que la seconde boule tirée soit rouge ?
	\item Quelle est la probabilité que la première boule tirée soit rouge sachant que la seconde est rouge ?
	\item On note $p_n(r,b)$ la probabilité d'obtenir une boule rouge au $n$-ème tirage quand l'urne contient initialement $r$ boules rouges et $b$ boules blanches. Pour tout entier $n \ge 1$, prouver que :
	\begin{center}
	$p_{n+1}(r,b) = \dfrac{r}{r+b} p_n(r+c,b) + \dfrac{b}{r+b} p_n(r,b+c)$. 
	\end{center}
	
	En déduire que :
	\begin{center}
	$\forall n \in \N^*, \p(R_n) = \dfrac{r}{r+b}$
	\end{center}
\end{enumerate}
\end{exemple}

\newpage

\section{Variables aléatoires}

Etant donnée une expérience aléatoire (modélisée par un espace probabilisé $(\Omega, \p)$), une \Strong{variable aléatoire} est une grandeur (en général numérique) liée à chaque résultat de l'expérience. Par exemple, si l'expérience aléatoire consiste à jeter deux dés, on peut s'intéresser à la somme $X$ obtenue, et s'intéresser ensuite à des probabilités liées à $X$, comme par exemple la probabilité que $X$ soit pair, que $X$ soit égal à une valeur donnée, ou inférieur ou égal à une valeur donnée... \\

Mathématiquement, une variable aléatoire sera une fonction définie sur l'ensemble $\Omega$ (souvent à valeurs réelles). Le terme "variable aléatoire" peut prêter à confusion. Ce n'est pas la fonction qui est aléatoire, mais plutôt son résultat, qui dépend du résultat (hasardeux) de l'expérience aléatoire.

\subsection{Définition. Loi d'une variable aléatoire}

\begin{definition}{Variable aléatoire}{}
Soit $(\Omega, \p)$ un espace probabilisé fini. On appelle \Strong{variable aléatoire} sur $\Omega$ toute application définie sur $\Omega$, à valeurs dans un certain ensemble $E$. Si l'ensemble $E$ est inclus dans $\R$, on parle de variable aléatoire \strong{réelle}.
\end{definition}

\begin{exemple}{}
Les fonctions constantes de $\Omega$ dans un ensemble $E$ sont des variables aléatoires appelées variables aléatoires certaines.
\end{exemple}

\begin{exemple}{}
Soit $A$ un événement de l'espace probabilisé $(\Omega,\p)$. La \Strong{fonction indicatrice} de $A$, notée $\bf{1}_A$, est définie par :
\begin{center}
$\forall \omega \in \Omega, \bf{1}_A(\omega) = \begin{cases} 1 \text{ si } \omega \in A \\ 0 \text{ sinon} \end{cases}$
\end{center}
est une variable aléatoire réelle sur $\Omega$, à valeurs dans $\{0,1\}$.
\end{exemple}

Le cas le plus courant est celui des variables aléatoires réelles. Il y a des notations réservées, en probabilité, aux variables aléatoires.

\begin{remarque}[Notation]{}
Soit $X$ une variable aléatoire, définie sur l'espace probabilisé $(\Omega, \p)$, à valeurs dans l'ensemble $E$. Si $A$ est une partie de $E$, rappelons qu'on note traditionnellement $X^{-1}(A)$ l'image réciproque de $A$ par $X$ ; c'est l'ensemble des éléments $\omega$ de $\Omega$ tels que $X(\omega) \in A$. 
\begin{center}
$X^{-1}(A) = \{\omega \in \Omega \mid X(\omega) \in A\}$.
\end{center}
\end{remarque}

En probabilité, cet événement est noté $\{X \in A \}$, et sa probabilité est notée $\p(X \in A)$ (on laisse tomber les accolades). On a donc 
\begin{center}
$\{X \in A \} = X^{-1}(A) = \{\omega \in \Omega \mid X(\omega) \in A\}$
\end{center}

Lorsque $A$ est un singleton $\{a\}$, on note plus simplement $\{X=a\}$ (au lieu de $\{X \in \{a\}\}$) l'image réciproque par $X$ du singleton $\{a\}$ (c'est l'ensemble des antécédents par $X$ de $a$, \ie l'ensemble des $\omega \in \Omega$ tels que $X(\omega) = a$), et on notera $\p(X = a)$ sa probabilité. \\

Dans le cas d'une variable aléatoire réelle, pour tout réel $a$, 
\begin{itemize}
\item On note $\{X \le a \}$ l'événement $\{X \in ]-\infty,a]\}$ et $\p(X \le a)$ sa probabilité. 
\item On note $\{X < a\}$ l'événement $\{X \in ]-\infty,a[\}$ et $\p(X < a)$ sa probabilité.
\item On note $\{X \ge a \}$ l'événement $\{X \in [a,+\infty[\}$ et $\p(X \ge a)$ sa probabilité.
\item On note $\{X > a\}$ l'événement $\{X \in ]a,+\infty[\}$ et $\p(X > a)$ sa probabilité.
\end{itemize}

\begin{exemple}[Exercice 8]{}
Soit $\Omega$ un ensemble fini, et $X$ une application de $\Omega \in \R$. Prouver que $X$ est combinaison linéaire de fonctions indicatrices.
\end{exemple}

\begin{remarque}[Petite Histoire : loi d'une variable aléatoire]{}
On se donne un espace probabilisé fini $(\Omega,\p)$ et $X$ une variable aléatoire sur $\Omega$, à valeurs dans un ensemble $E$. \\

Pour toute partie $A$ de $E$, posons 
\begin{center}
$\p_X(A) = \p(X \in A)$
\end{center}

On définit ainsi une fonction de l'ensemble des parties de $E$ dans $]0,1]$. Il est clair que $\p_X(E) = 1$ (puisque $\{X \in E\} = \Omega$). Par ailleurs, si $A$ et $B$ sont deux parties disjointes de $E$, les événements $\{X \in A\}$ et $\{X \in B\}$ sont évidemment incompatibles, et on a $\{X \in A \cup B\} = \{X \in A \} \cup \{X \in B\}$. On en déduit que
\begin{center}
$\p_X(A \cup B) = \p_X(A) + \p_X(B)$
\end{center}

\begin{definition}{}{}
Autrement dit, $\p_X$ définit une probabilité sur l'ensemble $E$ (du moins lorsque $E$ est fini), c'est cette probabilité qu'on appelle la \Strong{loi} de $X$.
\end{definition}

Précisons un peu les choses. Notons $X(\Omega)$ l'image directe de $\Omega$ par $X$, il s'agit d'une partie finie de $E$.

\begin{proposition}{}{}
la famille $(\{X=x\})_{x \in X(\Omega)}$ est un système complet d'événements. En particulier, $(\p(X = x))_{x \in X(\Omega)}$ est une famille de réels positifs de somme $1$.
\end{proposition}

\begin{demo}{}
Il est clair que les divers événements $\{X = x \}$ obtenus pour $x$ décrivant $X(\Omega)$ sont deux à deux disjoints (on ne peut avoir, pour un $\omega$ donné, $X(\omega) = x$ et $X(\omega) = y$ lorsque $x \ne y$), et de réunion $\Omega$ (si $\omega \in \Omega$, alors $\omega$ appartient évidemment à $\{X = X(\omega)\}$) \\

Si $A$ est une partie de $E$, on a alors 
\begin{center}
$\{X \in A \} = \displaystyle \bigcup_{x \in A \cap X(\Omega)} \{X=x\}$
\end{center}
et les divers ensembles qui interviennent dans cette réunion sont deux à deux disjoints. On en déduit par additivité finie que :
\begin{center}
$\p_X(A) = \p(X \in A) = \displaystyle \sum_{x \in A \cap X(\Omega)} \p(X=x)$.
\end{center}

Autrement dit, la fonction d'ensembles $\p_X$ (la loi de $X$) est entièrement déterminée par la connaissance des nombres $\p(X=x)$, obtenus pour $x$ décrivant $X(\Omega)$.

\end{demo}

\begin{definition}{}{}
Déterminer la loi de la variable aléatoire $X$, c'est déterminer $X(\Omega)$, et pour tout $x$ élément de $X(\Omega)$, donner $\p(X=x)$.
\end{definition}

Il peut parfois être malaisé de déterminer exactement l'ensemble $X(\Omega)$. On peut se contenter alors de trouver un ensemble fini $G$ tel que $X(\Omega) \subset G$, et de donner alors $\p(X = x)$, pour tout élément $x$ de $G$ (on trouvera $0$ pour les éléments $x \in G \setminus X(\Omega)$). \\

On va voir à présent que si on se donne une probabilité $\Q$ sur un ensemble fini $E$, on peut toujours trouver une variable aléatoire à valeurs dans $E$ dont la loi est $\Q$.

\begin{theoreme}{}{}
Soit $E$ un ensemble fini non vide, muni d'une probabilité $\Q$. Soit $\Omega$ un ensemble fini de cardinal supérieur ou égal à celui de $E$. Alors il existe une probabilité $\p$ sur $\Omega$, et une variable aléatoire $X$ de $\Omega$ dans $E$ telle que 
\begin{center}
$\forall x \in E, \p(X=x) = \Q(\{x\})$
\end{center}
\end{theoreme}

\begin{demo}{}
Notons $E=(x_1,\cdots,x_n)$, où $n = \text{Card } E$. On note aussi $q_i = \Q(\{x_i\})$, pour $1 \le i \le n$. \\
Notons $\Omega = \{\omega_1,\cdots,\omega_m\}$, où $m = \text{Card }\Omega \ge n$. Soit $\p$ l'unique probabilité sur $\Omega$ définie par 
\begin{center}
$\forall i \in \{1,\cdots,m\}, \p(\{\omega_i\}) = \begin{cases} q_i \text{ si } i \le n \\ 0 \text{ si } i > n \end{cases}$.
\end{center}

et définissons $X$ de $\Omega$ dans $E$ par 
\begin{center}
$\forall i \in \{1,\cdots,m\}, X(\omega_i) = \begin{cases} x_i \text{ si } i \le n \\ x_n \text{ si } i > n \end{cases}$
\end{center}

Soit $i$ un entier compris entre $1$ et $n$.
\begin{itemize}
	\item si $i < n$, on a $\{X = x_i\} = \{\omega_i\}$ et $\p(X = x_i) = q_i$
	\item si $i = n$, alors $\{X = x_n\} = \{\omega_n, \omega_{n+1},\cdots,\omega_m\}$, et donc 
	\begin{center}
	$\p(X=x_n) = \p(\{\omega_n\}) + \underbrace{\p(\{\omega_{n+1})}_{ = 0},\cdots,\underbrace{\p(\{\omega_m\})}_{= 0} = q_n$
	\end{center}
\end{itemize}

Remarque : si on veut juste une variable aléatoire $X$ de loi $\Q$, il suffit de prendre comme espace probabilisé $(E,\Q)$, et pour $X$ l'identité de $E$.

\begin{remarque}[Bilan]{}
Si on a un ensemble fini $E=\{x_1,\cdots,x_n\}$, et une famille $(p_1,\cdots,p_n)$ de réels positifs de somme 1, alors il existe une variable aléatoire $X$ définie sur un certain espace probabilisé $(\Omega,\p)$ telle que 
\begin{center}
$\forall i \in \{1,\cdots,n\}, \p(X=x_i) = p_i$
\end{center}
\end{remarque}
\end{demo}
\end{remarque}

\begin{exemple}{Loi uniforme}{}
Soit $E$ un ensemble fini. Une variable aléatoire $X$ (définie sur un certain espace probabilisé $(\Omega,\p)$) suit la \Strong{loi uniforme} sur $E$ si $X$ est à valeurs dans $E$ et prend chaque valeur de $E$ avec la même probabilité, autrement dit $\p_X$ est la probabilité uniforme sur $E$. Pour cela, il faut et il suffit que :
\begin{center}
$\forall x \in E, \p(X=x) = \dfrac{1}{\text{Card } E}$.
\end{center}

On écrira $X \hookrightarrow \mathcal{U}(E)$ pour signifier que $X$ suit la loi uniforme sur $E$.

\end{exemple}

\begin{exemple}{Loi de Bernoulli}{}

Soit $p$ un nombre compris entre $0$ et $1$. Une variable aléatoire $X$ suit la \Strong{loi de Bernoulli} de paramètre $p$ si $X$ est à valeurs dans $\{0,1\}$, et $\p(X=1) = p$  (donc $\p(X=0) = 1-p$). \\
On écrira $X \hookrightarrow \mathcal{B}(p)$ pour indiquer que $X$ suit la loi de Bernoulli de paramètre $p$. \\

Par exemple, si on joue à pile ou face, et que $X$ vaut $1$ si on est tombé sur "pile" et $0$ si on est tombé sur "face", alors $X$ suit la loi de Bernoulli de paramètre $p$, où $p$ est la probabilité d'apparition de "pile". \\

Plus généralement, si on a une épreuve de Bernoulli, la variable aléatoire qui vaut $0$ en cas d'échec, et $1$ en cas de succès est une variable de Bernoulli. \\

Si $A$ est un événement d'un espace probabilisé $(\Omega, \p)$, alors $\textbf{1}_A$ suit la loi de Bernoulli de paramètre $\p(A)$.

\end{exemple}

\begin{exemple}{Loi binomiale}{}

Cette loi apparaît naturellement lorsqu'on veut compter le nombre de succès lors d'une succession de $n$ épreuves de Bernoulli indépendantes, avec probabilité de succès $p$ lors de chaque épreuve. Modélisons une telle suite par l'univers $\{0,1\}^n$, muni de la probabilité $\p$ définie par
\begin{center}
$\forall \omega = (\omega_1,\cdots,\omega_n) \in \{0,1\}^n, \p(\{\omega\}) = p^\ell q^{n-\ell}$
\end{center}
où $\ell$ est le nombre de composantes qui valent $1$, et où $q=1-p$. \\

Soit $X$ l'application de $\Omega$ dans $\R$ qui à $\omega = (\omega_1,\cdots,\omega_n)$ associe le nombre de $1$ du $n$-uplet $\omega$ (c'est le nombre d'indices $i$ tels que $\omega_i = 1$). On voit aussi que $X(\omega)$ est la somme des $\omega_i$. Il est clair que $X$ est à valeurs dans $\{0,\cdots,n\}$. Pour $k$ entier compris entre $0$ et $n$, l'événement $\{X = k\}$ est l'ensemble des $n$-uplets $\omega$ qui ont exactement $k$ composantes égales à $1$. Un tel $\omega$ est entièrement déterminé par les places dans le $n$-uplet des $1$, il y a donc $\binom{n}{k}$ tels $n$-uplets (il s'agit de choisir $k$ numéros de places parmi $n$ possibles), et chacun de ces $n$-uplets est de probabilité $p^kq^{n-k}$. On en déduit que 
\begin{center}
$\p(X=k) = \binom{n}{k} p^kq^{n-k}$
\end{center}
\end{exemple}

On donne alors la définition suivante :
\begin{definition}{}{}
Soit $n \in \N^*$ et $p \in [0,1]$. Une variable aléatoire $X$ suit la loi binomiale de paramètres $n$ et $p$ si $X$ est à valeurs dans $\{0,\cdots,n\}$ et si (avec $q = 1 - p$) :
\begin{center}
$\forall k \in \{0,\cdots,n\}, \p(X=k) = \binom{n}{k}p^kq^{n-k}$
\end{center}
On écrit alors $X \hookrightarrow \mathcal{B}(n,p)$.
\end{definition}

\begin{exemple}{}
On lance deux dés, $X$ est la somme des deux résultats obtenus. Trouvons la loi de $X$. L'univers choisi est ici $\Omega = \{1,\cdots,6\}^2$, muni de la probabilité uniforme. Il est clair que $X$ est à valeurs dans $\{2,\cdots,12\}$. Il s'agit donc de compter, pour $2 \le k \le 12$, combien il y a de couples d'entiers de $\{1,\cdots,6\}$ dont la somme vaut $k$. On trouve :
\begin{align*}
\p(X=2) = \dfrac{1}{36} \quad & \quad \p(X=3) = \dfrac{2}{36} \\
\p(X=4) = \dfrac{3}{36} \quad & \quad \p(X=5) = \dfrac{4}{36} \\
\p(X=6) = \dfrac{5}{36} \quad & \quad \p(X=7) = \dfrac{6}{36} \\
\p(X=8) = \dfrac{5}{36} \quad & \quad \p(X=9) = \dfrac{4}{36} \\
\p(X=10) = \dfrac{3}{36} \quad & \quad \p(X=11) = \dfrac{2}{36} \\
\p(X=12) = \dfrac{1}{36} \quad & {}
\end{align*}
\end{exemple}

\begin{exemple}[Exercice 9]{}
Donner un exemple de variables aléatoires distinctes qui ont même loi.
\end{exemple}

\subsection{Espérance et variance d'une variable aléatoire réelle}

\subsubsection{Espérance}

\begin{definition}{Espérance}{}
Soit $X$ une variable aléatoire réelle, définie sur un univers probabilisé fini $(\Omega, \p)$. L'\Strong{espérance} de $X$, encore appelée \strong{valeur moyenne} de $X$, est le réel noté $\E(X)$ défini par : 
\begin{center}
$\E(X) = \displaystyle \sum_{x \in X(\Omega)} x\p(X=x)$
\end{center}
\end{definition}

On voit ainsi que $\E(X)$ est la moyenne pondérée des valeurs prises par $X$, le coefficient de pondération de chaque valeur étant la probabilité avec laquelle elle est prise par $X$. 
\begin{remarque}[Remarque utile]{}
Soit $X$ une variable aléatoire. Si $E$ est un ensemble fini qui contient l'ensemble fini des valeurs prises par $X$, on a aussi :
\begin{center}
$\E(X) = \displaystyle \sum_{x \in E} x \p(X=x)$
\end{center}
En effet, il est clair que $\p(X=x) = 0$ si $x$ n'est pas une valeur prise par $X$.
\end{remarque}

\begin{remarque}{}
On voit que l'espérance d'une variable aléatoire réelle dépend uniquement de la loi de cette variable aléatoire. Autrement dit, si $X$ et $Y$ sont deux variables aléatoires réelles de même loi ($X$ et $Y$ sont à valeurs dans un même ensemble $E$, et $\p(X=x) = \p(Y=x)$ pour tout élément $x$ de $E$), alors $\E(X) = \E(Y)$.
\end{remarque}

\begin{exemple}{}
Si $X$ est une variable aléatoire certaine, égale à un réel $a$, alors $\E(X) = a$.
\end{exemple}

\begin{exemple}{}
Si $X$ suit une loi uniforme sur un ensemble $E$, on aura 
\begin{center}
$\E(X) = \dfrac{1}{\text{Card } E} \displaystyle \sum_{x \in E} x$
\end{center}
\end{exemple}

\begin{exemple}{}
Soit $(\Omega, \p)$ un espace probabilisé fini, $X$ une variable aléatoire réelle sur $\Omega$. Si $X \hookrightarrow \mathcal{B}(p)$ alors $\E(X) = p$. \\

En particulier, si $A$ est un événement alors $\E(\textbf{1}_A) = \p(A)$.
\end{exemple}

\begin{exemple}[Exercice 10]{}
Soit $X$ une variable aléatoire qui suit une loi binomiale de paramètres $n$ et $p$. Alors 
\begin{center}
$\E(X) = np$
\end{center}
\end{exemple}

\begin{exemple}[Exercice 11]{}
Soit $n$ et $N$ deux entiers naturels tels que $1 \le n \le N$. On considère l'ensemble $\Omega$ des parties à $n$ éléments de l'ensemble $\{1,\cdots,N\}$. $X$ est l'application de $\Omega$ dans $\R$ définie par $X(A) = \max A$, pour tout $A \in \Omega$. Trouver la loi de $X$, et l'espérance de $X$.
\end{exemple}

Examinons les principales propriétés de l'espérance. On montre tout d'abord un lemme qui donne une expression alternative de l'espérance, utile pour prouver certaines propriétés.

\begin{lemme}{}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $X$ une variable aléatoire sur $\Omega$. On a :
\begin{center}
$\E(X) = \displaystyle \sum_{\omega \in \Omega} X(\omega) \p(\{\omega\})$
\end{center}
\end{lemme}

\begin{demo}{}
La famille $(\{X=x\})_{x \in X(\omega)}$ est un système complet d'événements, on a donc une partition de l'ensemble des indices $\Omega$. Donc, en sommant par paquets :
\begin{align*}
\sum_{\omega \in \Omega} X(\omega) \p(\{\omega\}) &= \sum_{x \in X(\Omega)} \left(\sum_{\omega \in \{X=x\}} \underbrace{X(\omega)}_{x}\p(\{\omega\})\right) \\
&= \sum_{x \in X(\Omega)} x \underbrace{\sum_{\omega \in \{X=x\}} \p(\{\omega\})}_{\p(\{X=x\})} \\
&= \sum_{x \in X(\Omega)} x \p(X=x) = \E(X)
\end{align*}
d'où le résultat.
\end{demo}

\begin{theoreme}{}{}
Soit $(\Omega, \p)$ un espace probabilisé fini, $X$ et $Y$ des variables aléatoires sur $\Omega$.
\begin{enumerate}
	\item Linéarité : pour tout réel $\alpha$, $\E(\alpha X + Y) = \alpha \E(X) + \E(Y)$
	\item Positivité : si $X$ est positive alors $\E(X) \ge 0$. De plus, $\E(X) = 0$ si et seulement si $\p(X=0) = 1$ : on dit que $X$ est nulle presque sûrement.
	\item Croissance : Si $X \le Y$ alors $\E(X) \le \E(Y)$
	\item On a : $\abs{\E(X)} \le \E(\abs{X})$
\end{enumerate}
\end{theoreme}

\begin{demo}{}
La première propriété résulte de la linéarité des sommes, en utilisant le lemme précédent. Cette propriété ne serait pas si facile à prouver sans le lemme. \\

Supposons $X$ positive, alors l'ensemble des valeurs prises par $X$ est inclus dans $\R_+$.
\begin{center}
$\E(X) = \displaystyle \sum_{x \in X(\Omega)} \underbrace{x \p(X=x)}_{\ge 0} \ge 0$, 
\end{center}
et comme une somme de réels positifs est nulle si et seulement si tous ses termes sont nuls, on voit que si $\E(X)$ est nul alors pour tout élément strictement positif $x$ de $X(\Omega)$, on a $\p(X=x) = 0$, ceci entraîne que
\begin{center}
$1 = \p(X=0) + \displaystyle \sum_{\substack{x \in X(\Omega) \\ x \ne 0}} \p(X=x) = \p(X=0)$
\end{center}

Réciproquement, si $\p(X=0) = 1$, alors pour tout $x$ non nul élément de $X(\Omega)$, on a $\p(X=x) = 0$, en effet :
\begin{center}
$1 = \p(X=0) + \displaystyle \sum_{\substack{x \in X(\Omega) \\ x \ne 0}} \p(X=x)$,
\end{center}
donc la somme de réels positifs $\displaystyle \sum_{\substack{x \in X(\Omega) \\ x \ne 0}} \p(X=x)$ est nulle, et tous ses termes sont nuls. On en déduit immédiatement que $\E(X) = 0$. \\

Les deux dernières propriétés (analogues à celles de l'intégrale) sont laissées en exercice.
\end{demo}

\begin{exemple}[Exercice 12]{}
Soient $X,Y$ des variables aléatoires réelles, sur un espace probabilisé fini $(\Omega, \p)$. Prouver l'inégalité de \textsc{Cauchy-Schwarz} :
\begin{center}
$\abs{E(XY)} \le \sqrt{\E(X^2)}\sqrt{E(Y^2)}$
\end{center}
On pourra s'inspirer de la preuve vue pour les intégrales.
\end{exemple}

\begin{corollaire}{}{}
Si $X$ est une variable aléatoire réelle, alors pour tous réels $\alpha$ et $\beta$, on a 
\begin{center}
$\E(\alpha X + \beta) = \alpha \E(X) + \beta$
\end{center}
\end{corollaire}

\begin{definition}{Variable aléatoire réelle centrée}{}
Une variable aléatoire réelle $X$ est dite \Strong{centrée} lorsque $\E(X) = 0$.
\end{definition}

La proposition qui suit est immédiate.

\begin{proposition}{}{}
Si $X$ est une variable aléatoire réelle, alors $X-\E(X)$ est centrée
\end{proposition}

L'inégalité qui suit est assez utile (surtout à vrai dire une de ses variantes connue sous le nom de l'inégalité de \textsc{Bienaymé-Tchebychev}, voir le paragraph sur la variance), bien que pas très précise.

\begin{theoreme}{Inégalité de Markov}{}
Soit $X$ une variable aléatoire réelle positive, définie sur l'espace probabilisé fini $(\Omega, \p)$, et $\varepsilon$ un réel strictement positif. Alors 
\begin{center}
$\p(\{X \ge \varepsilon\}) \le \dfrac{\E(X)}{\varepsilon}$
\end{center}
\end{theoreme}

\begin{demo}{}
On a $X \ge \varepsilon \textbf{1}_{\{X \ge \varepsilon\}}$ : notons en effet $A$ l'événement $\{X \ge \varepsilon\}$. Soit $\omega$ un élément de $\Omega$ : 
\begin{itemize}
	\item Si $\omega \in A$, alors $X(\omega) \ge \varepsilon$, et $\varepsilon \textbf{1}_A(\omega) = \varepsilon$
	\item Si $\omega \not \in A$, alors $\varepsilon \textbf{1}_A(\omega) = 0$, et $X(\omega) \ge 0$
\end{itemize}

On en déduit par croissance de l'espérance :
\begin{center}
$\E(X) \ge \varepsilon \E(\textbf{1}_A) = \varepsilon \p(A) = \varepsilon \p(\{X \ge \varepsilon \})$
\end{center}
d'où le résultat.
\end{demo}

\begin{remarque}{}
L'inégalité de Markov n'a d'intérêt que si $\dfrac{\E(X)}{\varepsilon}$ est inférieur ou égal à $1$...
\end{remarque}

Le théorème qui suit est très utile, il permet le calcul de l'espérance d'une variable aléatoire du type $f(X)$, où $X$ est une variable aléatoire en connaissant seulement la loi de $X$ (et non celle de $f(X)$ qui peut être compliquée à calculer).

\pagebreak

\begin{theoreme}{Formule de transfert}{}
Soit $(\Omega, \p)$ un espace probabilisé fini, $E$ un ensemble, $X$ une application de $\Omega$ dans $E$ ($X$ est donc une variable aléatoire), $f$ une application de $E$ dans $\R$. On note $f(X)$ la variable aléatoire réelle $f\circ X$. Alors 
\begin{center}
$\E(f(X)) = \displaystyle \sum_{x \in X(\Omega)} f(x) \p(X=x)$
\end{center}
\end{theoreme}

\begin{demo}{}
On utilise à nouveau la famille $(\{X = x\})_{x \in X(\Omega)}$, qui est un système complet d'événements, on a donc une partition de l'espace $\Omega$. En utilisant le lemme, on a 
\begin{center}
$\E(f(X)) = \displaystyle \sum_{\omega \in \Omega} f(X(\omega)) \p(\{\omega\})$
\end{center}

En sommant par paquets, il vient alors :
\begin{center}
$\E(f(X)) = \displaystyle \sum_{x \in X(\Omega)} \left(\sum_{\omega \in \{X = x\}} f(X(\omega)) \p(\{\omega\})\right)$
\end{center}

Soit $x$ un élément de $X(\Omega)$. Pour tout élément $\omega$ de $\{X=x\}$, on a $X(\omega) = x$ \footnotemark, donc
\begin{center}
$\displaystyle \sum_{\omega \in \{X=x\}} f(X(\omega))\p(\{\omega\}) = \sum_{\omega \in \{X=x\}} f(x) \p(\{\omega\}) = f(x) \sum_{\omega \in \{X=x\}} \p(\{\omega\}) = f(x) \p(\{X=x\})$
\end{center}
ce qui entraîne la formule.
\end{demo}

\footnotetext{Comme l'a magnifiquement écrit M. Sellès dans son magnifique poly : "This is f******** obvious". En tant que 1/2 naïf qui lit les poly de M. Sellès en pensant que le cours était tapé par notre Grand Sensei, je me mis à douter de l'auteur du document : mais non, c'était bien lui. En fait, c'est plutôt logique : de la même façon que Mme Zmihi critique les Américains (cette histoire viendra peut-être), M. Sellès a un jour lancé en plein cours : "This is fucking true !".}

\begin{remarque}[Remarque utile]{}
Avec les notations du théorème, si $F$ est un ensemble fini qui contient $X(\Omega)$, on a également :
\begin{center}
$\E(f(X)) = \displaystyle \sum_{x \in F} f(x) \p(X=x)$
\end{center}
car pour tout $x \in F \setminus X(\Omega)$, $\p(X=x) = 0$.
\end{remarque}

\begin{exemple}[Exercice 13]{}
Soit $X$ une variable aléatoire réelle qui suit la loi uniforme sur $\{1,\cdots,n\}$. Calculer $\E(X)$ et $\E(X^2)$
\end{exemple}

\begin{exemple}[Exercice 14]{}
Si $X$ est une variable aléatoire réelle telle que $X \hookrightarrow \mathcal{B}(n,p)$, calculer $\E(X)$ et $\E(X^2)$.
\end{exemple}

Voici une application intéressante de la formule de transfert :
\begin{proposition}{Espérance d'un produit}{}
Soit $(\Omega, \p)$ un espace probabilisé fini, $X$ et $Y$ deux variables aléatoires réelles sur $\Omega$. On a
\begin{center}
$\E(XY) = \displaystyle \sum_{(x,y) \in X(\Omega) \times Y(\Omega)} xy \p(\{X = x\} \cap \{Y = y\})$
\end{center}
\end{proposition}

\begin{demo}{}
Notons $Z$ la variable aléatoire à valeurs dans $\R^2$ définie par :
\begin{center}
$\forall \omega \in \Omega, Z(\omega) = (X(\omega,Y(\omega))$
\end{center}

Soit d'autre part $f$ l'application de $\R^2$ dans $\R$ définie par :
\begin{center}
$\forall (x,y) \in \R^2, f(x,y) = xy$.
\end{center}

On a alors $XY = f(Z)$, et on cherche $\E(f(Z))$. \\

Il est clair que $Z(\Omega)$ est inclus dans l'ensemble fini $E = X(\Omega) \times Y(\Omega)$ (mais l'inclusion peut être stricte, voir l'exemple qui suit), on en déduit, d'après la formule de transfert : 
\begin{center}
$\E(f(Z)) = \displaystyle \sum_{z \in E} f(z) \p(Z=z) = \sum_{(x,y) \in E} xy \p(Z=(x,y))$
\end{center}

Par ailleurs, l'événement $Z=(x,y)$ n'est autre que $\{X = x\} \cap \{Y = y\}$.
\end{demo}

\begin{exemple}{}
Soit $X$ une variable aléatoire qui suit la loi de Bernoulli $\mathcal{B}(1/2)$, et $Y = 1-X$. \\

Si $Z = (X,Y)$, alors $Z(\Omega) = \{(0,1),(1,0)\}$, est strictement inclus dans $\{0,1\}^2$.
\end{exemple}

	
\end{document}
