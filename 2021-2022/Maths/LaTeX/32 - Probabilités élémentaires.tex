\documentclass[12pt,a4paper]{report}

\input{00 - preambule}

\begin{document}

\newcommand{\p}{\mathbb{P}}

\section*{Introduction}

La théorie des probabilités a pour objet la modélisation mathématique du hasard, des expériences aléatoires. \\
Une expérience aléatoire est une expérience qui a plusieurs résultats possibles (on dit aussi issues) qu'on ne peut prévoir avec certitude, mais qui présente (c'est 
crucial) une régularité statistique sur le long terme. Il est postulé ici notamment la possibilité de répéter l'expérience un grand nombre de fois, dans des 
conditions identiques (dans l'idéal), de façon indépendante (les différentes répétitions n'ont aucune influence les unes sur les autres). \\
On prend un exemple. Une des expériences aléatoires les plus simples est le jeu de pile ou face : lorsqu'on jette une pièce de monnaie et qu'on regarde quel côté de 
la pièce apparaît, il n'y a que deux issues possibles (pile ou face), et on ne peut prévoir avec certitude quel côté de la pièce apparaît avant de l'avoir lancée. Si 
on jette la même pièce un grand nombre de fois, il semble que la proportion du nombre de piles parmi le nombre total se rapproche d'un nombre fixe (0.5 en général si 
la pièce est équilibrée, un autre nombre sinon), ce qui conduit à définir un nombre qui mesure le degré de vraisemblance d'apparition de pile pour un lancer donné 
(c'est ce qu'on appellera la probabilité d'apparition de pile). Le fait que le hasard fonctionne ainsi résulte de l'expérience (vous pourriez chacun jeter 500 fois 
une pièce de monnaie et consigner combien de fois vous avez obtenu pile dans la série de lancers ; si on fait la moyenne des 47 proportions obtenues, on ne sera pas 
très loin de 0.5...) \\
La modélisation mathématique des phénomènes aléatoires comporte trois ingrédients principaux : 
\begin{enumerate}
	\item L'espace d'états, ou univers, noté traditionnellement $\Omega$ ; c'est l'ensemble de toutes les issues possibles de notre expérience aléatoire. Prenons quelques exemples : 
	\begin{itemize}
		\item Un jeu de pile ou face aura pour univers l'ensemble $\Omega = \{P,F\}$, ou $\Omega = \{0,1\}$. L'expérience aléatoire qui consiste à jeter $n$ fois une 
		pièce, et à collecter les résultats des $n$ lancers se modélise en prenant pour univers $\Omega = \{P,F\}^n$. Un résultat est une suite $\omega = (\omega_1,\cdots,\omega_n)$ d'éléments de $\{P,F\}$.
		\item On modélise l'expérience aléatoire qui consiste à lancer deux dés en prenant pour univers l'ensemble $\Omega = \{1,2,3,4,5,6\}^2$.
		\item L'expérience aléatoire qui consiste à tirer avec remise $n$ boules d'une urne qui contient $N$ boules distinctes (numérotées de $1$ à $N$) aura pour 
		univers $\Omega = \{1,\cdots,N\}$
		\item L'expérience aléatoire qui consiste à tirer en succession et sans remise $n$ boules d'une urne qui contient $N$ boules distinctes (numérotées de $1$ à 
		$N$) aura pour univers l'ensemble des $n$-arrangements d'éléments de $\{1,\cdots,N\}$
		\item L'expérience aléatoire qui consiste à tirer une poignée de $n$ boules dans une urne qui en contient $N$ numérotées de $1$ à $N$ aura pour univers 
		naturel l'ensemble des parties à $n$ éléments de l'ensemble $\{1,\cdots,N\}$ 
		\item L'expérience aléatoire consistant à mesurer la durée de vie d'une ampoule électrique a pour univers $\Omega = \R_+$
	\end{itemize}
	
	Cette année, on s'occupera uniquement du cas où l'ensemble $\Omega$ est fini (cela simplifie beaucoup la théorie mais permet quand même d'en introduire tout le vocabulaire et pas mal d'aspects).
	
	\item Les événements. Un événement est une propriété, vérifiée ou non une fois l'expérience aléatoire réalisée. Par exemple, si on jette deux dés, on peut 
	s'intéresser à l'événement : "la somme des résultats obtenus est un nombre inférieur ou égal à 4". Mathématiquement, un événement sera modélisé par l'ensemble des 
	issues qui le réalisent, c'est donc une partie de l'univers $\Omega$. L'événement de notre exemple est ainsi modélisé par l'ensemble 
	\begin{center}
	$\{(1,1),(1,2),(2,1),(1,3),(3,1),(2,2)\}$
	\end{center}
	Lorsque $\Omega$ est fini, l'ensemble des événements est l'ensemble $P(\Omega)$ des parties de $\Omega$. Il y a un langage propre à la théorie :
	\begin{itemize}
		\item Les événements $\{\omega\}$ (singletons) s'appellent les événements élémentaires.
		\item Si $A$ est un événement, et si l'expérience aléatoire a donné l'issue $\omega$, la traduction de "l'événement $A$ est réalisé" est : $\omega \in A$. 
		\item L'univers $\Omega$ s'appellent l'événement certain, $\varnothing$ est l'événement impossible.
		\item Si $A$ et $B$ sont deux événements, $A \cup B$ est l'événement "$A$ ou $B$", $A \cap B$ est l'événement "$A$ et $B$", et le complémentaire de $A$, noté $\overline{A}$ ou $A^c$ s'appelle l'événement contraire de $A$. Les événements $A$ et $B$ sont incompatibles lorsque $A \cap B = \varnothing$. On dit que $A$ implique $B$ lorsque $A \subset B$.
	\end{itemize}
	
	\item La probabilité $\p$ : à chaque événement $A$ est attaché un nombre $\p(A)$, élément de $[0,1]$, qui mesure le degré de vraisemblance de $A$ (ce nombre est 
	d'autant plus proche de $1$ que les chances que $A$ se produise sont élevées). \\
	
	Reprenons notre approche fréquentielle : répétons l'expérience aléatoire $n$ fois, on note $f_n(A)$ la fréquence de réalisation de l'événement $A$ (c'est le 
	quotient du nombre de fois où $A$ s'est produit par $n$, nombre total de réalisations de l'expérience). On prend alors :
	\begin{center}
	$\p(A) = \underset{n \to +\infty}{\lim} f_n(A)$
	\end{center}
	en postulant l'existence de cette limite. D'après les propriétés des fréquences, on aura alors $\p(\Omega) = 1$ et $\p(A \cup B) = \p(A)+\p(B)$ lorsque $A$ et $B$ 
	sont disjoints. C'est ce qui va nous conduire à la définition rigoureuse d'une probabilité. Le postulat de régularité statistique ne sert qu'à justifier les 
	définitions mathématiques qui vont suivre. Un des aspects très satisfaisant de la théorie est qu'en retour on peut démontrer cette régularité statistique (ce sont 
	les résultats connus sous le nom de loi des grands nombres).
\end{enumerate}

Il y a aussi un quatrième ingrédient, dont nous reparlerons plus tard : les variables aléatoires.

\newpage

\section{Probabilités sur un univers fini}

\subsection{Espaces probabilisés}

\begin{definition}{Probabilité}{}
Soit $\Omega$ un ensemble (univers) fini. On appelle \Strong{probabilité} sur $\Omega$ toute application $\p$ de $P(\Omega)$ dans $[0,1]$ telle que :
\begin{enumerate}
\item $\p(\Omega) = 1$
\item Si $A$ et $B$ sont deux événements incompatibles, $\p(A \cup B) = \p(A) + p(B)$ (additivité)
\end{enumerate}
\end{definition}

\begin{definition}{Espace probabilisé}{}
On appelle \Strong{espace probabilisé fini} tout couple $(\Omega,\p)$ où $\Omega$ est un univers fini et $\p$ une probabilité sur $\Omega$.
\end{definition}

\begin{remarque}{}
Il y a un vocabulaire attaché à la probabilité, un peu artificiel quand on a affaire à des ensembles finis, mais qu'on donne quand même. \\
Soit $(\Omega,\p)$ un espace probabilisé fini. \\
On dit qu'un événement $A$ est \Strong{négligeable} lorsque $\p(A) = 0$ et \Strong{quasi certain} si $\p(A) = 1$. \\
Une propriété sur $\Omega$ est vraie \Strong{presque sûrement} si l'ensemble des points $\omega$ où la propriété est fausse est négligeable. \\

On peut se poser la question de l'existence dans le cas fini d'événements négligeables autres que l'événement impossible. En effet, la modélisation conduit en général
à attribuer à chaque événement élémentaire une probabilité strictement positive, mais rien n'empêche d'ajouter artificiellement des issues de probabilité nulle. Dans 
le cas d'ensembles infinis (non dénombrables), la situation est bien différente. Par exemple, si on modélise un jeu de pile ou face infini (c'est un idéal 
mathématique, évidemment), on est amené à considérer l'ensemble non dénombrable $\Omega = \{0,1\}^\N$ (ensemble des suites infinies d'éléments de $\{0,1\}$). On 
démontre qu'on peut munir $\Omega$ d'une probabilité $\p$ conforme à notre intuition (par exemple, la probabilité d'obtenir "pile" à un lancer donné est de $\dfrac{1}{2}$, 
la probabilité que les $n$ premiers lancers aient des valeurs données est $\dfrac{1}{2^n}$). Alors on montre facilement que la probabilité de chaque événement 
élémentaire est nulle, de même que celle d'obtenir "pile" tous les trois lancers. Il y a bien dans ce cas des événements négligeables qui ne sont pas l'événement 
impossible.

\end{remarque}

\pagebreak

Donnons tout de suite les principales propriétés des probabilités :

\begin{proposition}{Propriétés principales des probabilités}{}

Soit $(\Omega,\p)$ un espace probabilisé fini, $A$ et $B$ deux événements.
\begin{enumerate}
	\item $\p(\varnothing) = 0$
	\item $\p(\overline{A}) = 1- \p(A)$.
	\item Si $A \subset B$, alors $\p(A) \le \p(B)$ (on dit que $\p$ est \strong{croissante}). \\
	Plus précisément, on a $\p(B \setminus A) = \p(B) - \p(A)$ lorsque $A \subset B$.
	\item $\p(A \cup B) = \p(A) + \p(B) - \p(A \cap B)$
	\item Si $A_1,\cdots,A_n$ sont des événements deux à deux incompatibles, alors (additivité finie) :
	\begin{center}
	$\displaystyle \p \left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n \p(A_k)$
	\end{center}
	
	\item Si $A_1,\cdots,A_n$ sont des événements quelconques, alors (inégalité de Boole) :
	\begin{center}
	$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) \le \sum_{k=1}^N \P(A_k)$
	\end{center}
\end{enumerate}

\end{proposition}

\begin{demo}{}
Soient $A$ et $B$ deux événements tels que $A \subset B$. Alors $B$ est réunion disjointe de $A$ et de $B \setminus A$, donc 
\begin{center}
$\p(B) = \p(A \cup (B \setminus A)) = \p(A)+\underbrace{\p(B \setminus A)}_{\ge 0}$,
\end{center}

et ceci donne les trois premières assertions (prendre $A = B = \varnothing$ pour la première, $B = \Omega$ pour la deuxième). \\
À présent, si $A$ et $B$ sont deux événements quelconques, on observe que $A \cup B$ est réunion disjointe de $A$ et de $B \setminus (A \cap B)$ \footnotemark, d'où
\begin{center}
$\p(A \cup B) = \p(A) + \p(B \setminus (A \cap B)) = \p(A) + \p(B) - \p(A \cap B)$
\end{center}

Les deux dernières assertions se prouvent facilement par récurrence.
\end{demo}

\footnotetext{Faire un dessin pour le voir.}

\begin{definition}{Système complet d'événements}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A_1,\cdots,A_n$ des événements. \\
On dit que $(A_1,\cdots,A_n)$ est un \Strong{système complet d'événements} si les $A_i$ sont deux à deux incompatibles et si la réunion des $A_i$ est $\Omega$.
\end{definition}

\begin{remarque}{}
Si $(A_1,\cdots,A_n)$ est un système complet d'événements, on a par additivité finie :
\begin{center}
$1 = \p(\Omega) = \displaystyle \sum_{k=1}^n \p(A_k)$
\end{center}
\end{remarque}

\begin{exemple}{}
Pour tout événement $A$ d'un espace probabilisé fini $(\Omega,\p)$, $(A, \overline{A})$ est un système complet d'événements.\\ 
De même, $({\omega})_{\omega \in \Omega}$ est aussi un système complet d'événements.
\end{exemple}

\begin{proposition}{}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $(A_1,\cdots,A_n)$ un système complet d'événements. Alors, pour tout événement $B$, on a :
\begin{center}
$\p(B) = \displaystyle \sum_{k=1}^n \p(B \cap A_k)$
\end{center}
\end{proposition}

\begin{demo}{}
Soit $B$ un événement. On a :
\begin{center}
$B = B \cap \Omega = B \cap \displaystyle \bigcup_{k=1}^n A_k = \bigcup_{k=1}^n (B \cap A_k)$
\end{center}

et les divers ensembles $B \cap A_1,\cdots,B\cap A_n$ sont deux à deux disjoints, d'où le résultat par additivité finie.
\end{demo}

\begin{exemple}[Exercice 1]{}
La proposition précédente reste vraie si on suppose seulement que les $A_i$ sont deux à deux incompatibles et que leur réunion est un événement quasi-certain.
\end{exemple}

\begin{exemple}[Exercice 2]{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A$ et $B$ deux événements tels que $\p(A) = \dfrac{3}{4}$ et $\p(B) = \dfrac{1}{3}$. \\
Prouver que $\dfrac{1}{12} \le \p(A \cap B) \le \dfrac{1}{3}$. \\

Preuve : on a déjà $\p(A \cap B) = \p(A) + \p(B) - \underbrace{\p(A \cup B)}_{\text{positif et inférieur ou égal à 1}} \ge \dfrac{3}{4}+\dfrac{1}{3}-1 = \dfrac{1}{12}$. \\

De plus, l'événement $A \cap B$ implique l'événement $B$, donc $\p(A \cap B) \le \p(B) = \dfrac{1}{3}$.

\end{exemple}

\begin{exemple}[Exercice 3]{}
Soit $\Omega,\p)$ un espace probabilisé fini, $A_1,\cdots,A_n$ des événements (avec $n \ge 2$). \\
Prouver que
\begin{center}
$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) \ge \sum_{k=1}^n \p(A_k) - \sum_{1 \le k < \ell \le n} \p(A_k \cap A_\ell)$
\end{center}
\end{exemple}

\begin{exemple}[Exercice 4]{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A,B,C$ des événements. Prouver que
\begin{center}
$\p(A \cup B \cup C) = \p(A) + \p(B) + \p(C) - \p(A \cap B) - \p(B \cap C) - \p(A \cap C) + \p(A \cap B \cap C)$
\end{center}
\end{exemple}

Le résultat de l'exercice suivant n'est pas officiellement au programme, mais il est utile, c'est conseillé de le retenir : 

\begin{exemple}[Exercice 5]{Formule de Poincaré}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A_1,\cdots,A_n$ des événements (avec $n \ge 2$). \\
Prouver que :
\begin{center}
$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n (-1)^{k-1} \left(\sum_{1 \le i_1 < \cdots < i_k \le n} \p(A_{i_1} \cap \cdots A_{i_n})\right)$
\end{center}

La somme intérieure porte sur les suites strictement croissantes de $k$ entiers de $\{1,\cdots,n\}$. L'ensemble de ces suites est en bijection avec l'ensemble des 
parties à $k$ éléments de $\{1,\cdots,n\}$ (il n'y a qu'une seule façon de classer par ordre croissant les éléments d'une partie de $\{1,\cdots,n\}$). La somme 
intérieure est donc la somme des probabilités de toutes les intersections possibles de $k$ ensembles parmi $A_1,\cdots,A_n$, elle comporte $\begin{pmatrix} n \\ k\end{pmatrix}$ termes. 
Le premier terme de la somme (obtenu pour $k = 1$) est la somme des probabilités des ensembles $A_1,\cdots,A_n$, affectée d'un signe $+$. Il y a ensuite alternance de 
signes entre deux termes consécutifs. Le dernier terme est $(-1)^{n-1}\p(A_1 \cap \cdots \cap A_n)$. \\

On a l'écriture alternative suivante (en notant, pour $k \in \{1,\cdots,n\}$, $\mathcal{P}_k(n)$ l'ensemble des parties à $k$ éléments de l'ensemble $\{1,\cdots,n\}$) :
\begin{center}
$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n (-1)^{k-1} \left(\sum_{I \in \mathcal{P}_k(n)} \p\left(\bigcap_{\ell \in I}\right)\right)$
\end{center}

Indice : par récurrence.

\end{exemple}

\begin{remarque}[Petite histoire]{}
Donnons-nous dans un premier temps un ensemble fini $\Omega$.
\begin{itemize}
	\item Soit $\p$ une probabilité sur $\Omega$. Si $A$ est un événement, alors $A$ est réunion disjointe des singletons formés d'un élément de $A$, on a donc, par 
	additivité finie : 
	\begin{center}
	$\p(A) = \displaystyle \sum_{\omega \in A} \p(\{\omega\})$
	\end{center}
	
	On voit donc que $\p$ est entièrement déterminée par sa valeur sur les événements élémentaires. \\
	
	De plus, pour chaque élément $\omega$ de $\Omega$, on a $\p(\{\omega\}) \ge 0$ et $1 = \p(\Omega) = \displaystyle \sum_{\omega \in \Omega} \p(\{\omega\})$.
	
	\item Réciproquement, si on se donne une famille $(p_\omega)_{\omega \in \Omega}$ de nombres réels positifs ou nuls, indexée par $\Omega$, de somme 1, et si on pose, pour $A \in \mathcal{P}(\Omega)$,
	\begin{center}
	$\p(A) = \displaystyle \sum_{\omega \in A} p_\omega$
	\end{center}
	on vérifie sans difficulté aucune qu'on définit bien de cette manière une probabilité sur l'ensemble fini $\Omega$ (exercice).
\end{itemize}
\end{remarque}

Résumons :

\begin{theoreme}{}{}
Se donner une probabilité sur l'ensemble fini $\Omega$ revient à se donner une famille $(p_\omega)_{\omega \in \Omega}$ de nombres réels positifs ou nuls de somme 1. \\
Plus précisément, si on dispose d'une telle famille, il y a une et une seule probabilité $\p$ sur $\Omega$ telle que $\p(\{\omega\}) = p_\omega$ pour tout élément $\omega$ de $\Omega$.
\end{theoreme}

Examinons à présent une situation courante, celle où toutes les issues possibles ont même probabilité : 

\begin{theoreme}{Probabilité uniforme}{}
Soit $\Omega$ un ensemble fini. Il existe une et une seule probabilité $\p$ sur $\Omega$, appelée \Strong{probabilité uniforme}, qui a la même valeur sur tous les 
singletons. \\
On a, pour tout élément $\omega$ de $\Omega$, et pour tout événement $A$ :
\begin{center}
$\p(\{\omega\}) = \dfrac{1}{\text{Card } \Omega}$ et $\p(A) = \dfrac{\text{Card } A}{\text{Card } \Omega}$
\end{center}
\end{theoreme}

\begin{demo}{}
Si $\p$ existe, on doit avoir, en notant $p$ la valeur commune de $\p$ sur les singletons,
\begin{center}
$1 = \p(\Omega) = \displaystyle \sum_{\omega \in \Omega} \p(\{\omega\}) = \sum_{\omega \in \Omega} p = p \text{Card } \Omega$
\end{center}
Donc $p = \dfrac{1}{\text{Card } \Omega}$. \\

Si maintenant on pose, pour $\omega \in \Omega$, $p_\omega = \dfrac{1}{\text{Card } \Omega}$, on a là une famille de réels positifs de somme 1, il existe donc une 
unique probabilité $\p$ sur $\Omega$ telle que
\begin{center}
$\forall \omega \in \Omega, \p(\{\omega\}) = \dfrac{1}{\text{Card} \Omega}$
\end{center}
et on a bien, pour tout événement $A$,
\begin{center}
$\p(A) = \displaystyle \sum_{\omega \in A} \p(\{\omega\}) = \sum_{\omega \in A} \dfrac{1}{\text{Card } \Omega} = \dfrac{\text{Card } A}{\text{Card } \Omega}$
\end{center}
\end{demo}

\begin{remarque}{}
Chaque fois qu'un énoncé fait référence à des tirages ou des choix "au hasard", à des dés "équitables, ou équilibrés, ou non truqués", à des pièces "équilibrées, ou 
non truquées" (pour les jeux de pile ou face), à des boules ou des jetons "indiscernables" (pour des énoncés à bases de tirages dans des urnes), c'est qu'on a affaire 
à une situation d'équiprobabilité, et on munira donc l'univers correspondant de la probabilité uniforme. \\

Le terme "tirage au hasard" n'est pas très bien choisi, le hasard n'est pas toujours synonyme d'équiprobabilité. Par exemple, si l'expérience aléatoire consiste à 
jeter deux dés et à noter la somme des deux résultats obtenus (l'univers est donc l'ensemble des entiers compris entre 2 et 12), il est clair que qu'on a pas affaire 
à une situation d'équiprobabilité, bien que le "hasard" soit toujours à l'œuvre.
\end{remarque}

\begin{remarque}{}
Dans le cas de la probabilité uniforme, la formule $\p(A) = \dfrac{\text{Card } A}{\text{Card } \Omega}$ se lit quelquefois "nombre de cas favorables sur nombre de 
cas possibles" (un cas favorable est une issue qui réalise l'événement $A$). Dans cette situation (très souvent rencontrée), calculer une probabilité, c'est faire du 
dénombrement.
\end{remarque}

\begin{remarque}{}
Un grand nombre d'énoncés aiment à contextualiser la situation : on parle de lancer de dés, de jets de pièces, de tirages dans des urnes. M. Sellès est enclin à 
éviter ce genre d'énoncé, et rester dans le domaine mathématique pur et dur, mais il faut quand même vous préparer à les affronter. Dans ce cas là, c'est à vous de 
préciser quel univers vous adoptez pour modéliser la situation, et aussi quelle probabilité vous considérez sur cet univers. Revenons sur les modèles à base de 
tirages dans des urnes, pour les trois cas les plus simples :
\begin{enumerate}
	\item Si on effectue $n$ tirages avec remise (chaque tirage a lieu en succession, et on remet la boule tirée dans l'urne après chaque tirage) dans une urne qui 
	contient $N$ boules, on prend en général comme univers $\Omega = \{1,\cdots,N\}^n$ et on considère que chaque tirage est équiprobable. Dans ce cas, 
	$\text{Card } \Omega = N^n$. On peut très bien simuler ainsi un jeu de pile ou face (considérer une urne qui contient deux boules).
	\item Si on effectue $n$ tirages successifs sans remise (chaque tirage a lieu en succession, et on garde la boule tirée dans l'urne après chaque tirage) dans une 
	urne qui contient $N$ boules, on prend comme univers $\Omega$ l'ensemble des $n$-uplets d'entiers distincts de $\{1,\cdots,N\}$ (on imagine qu'on a numéroté les 
	$N$ boules), c'est-à-dire les $n$-arrangements de l'ensemble $\{1,\cdots,N\}$, et dans ce cas, $\text{Card}  \Omega = N(N-1) \cdots (N-n+1)$
	\item Si on effectue des tirages simultanés de $n$ boules (on tire des poignées de $n$ boules) dans une urne qui en contient $N$, l'univers $\Omega$ adéquat est 
	en général l'ensemble des parties à $n$ éléments de l'ensemble des $N$ boules, et on a dans ce cas $\text{Card } \Omega = \begin{pmatrix} N \\ n \end{pmatrix}$.
\end{enumerate}
Notons que les fameuses urnes peuvent aussi servir à modéliser des situations non équiprobables (même si les tirages le sont). C'est souvent le cas lorsque l'ensemble 
des boules est divisé en une ou plusieurs sous-populations (caractérisées, en général, par la couleur). Si on vous dit par exemple qu'une urne contient 7 boules, dont 
4 vertes et 3 rouges, et que l'expérience aléatoire consiste à tirer une boule, et à noter sa couleur, on peut prendre comme univers $\Omega = \{V,R\}$ avec $\p(V) = \dfrac{4}{7}$ et $\p(R) = \dfrac{3}{7}$, on a ainsi modélisé un jeu de pile ou face non équitable.
\end{remarque}

\begin{exemple}[Exercice 6]{}
Une urne contient 6 boules rouges, 5 boules vertes et 3 boules bleues.
\begin{enumerate}
	\item On tire simultanément trois boules de l'urne. Quelle est la probabilité d'avoir un tirage unicolore ? Quelle est la probabilité d'avoir un tirage 
	tricolore ? Quelle est la probabilité d'avoir un tirage bicolore ?
	
	$\rightarrow$ Pour avoir un tirage unicolore, il faut soit tirer trois rouges, soit trois bleues, soit trois vertes. La probabilité de tirer trois rouges vaut $\dfrac{6}{14}\dfrac{5}{13}\dfrac{4}{12} = \dfrac{5}{91}$, la probabilité de tirer trois bleues est $\dfrac{3}{14} \dfrac{2}{13} \dfrac{1}{12} = \dfrac{1}{364}$ et celle de tirer trois vertes vaut $\dfrac{5}{14}\dfrac{4}{13}\dfrac{3}{12} = \dfrac{5}{182}$. Donc la probabilité d'obtenir un tirage unicolore vaut $\dfrac{5}{91} + \dfrac{5}{182} + \dfrac{1}{364} = \dfrac{31}{364}$. \\
	
	Tirage tricolore : la première boule n'importe pas, elle est de la couleur qu'on veut.
	Si elle est rouge, alors il faut tirer une verte et une bleue. Si la deuxième est bleue, la troisième doit être verte. probabilité de tout ceci : $\dfrac{6}
{14}\dfrac{3}{13}\dfrac{5}{12} = \dfrac{5}{364}$. \\
	Si la deuxième est verte, la troisième est bleue. Probabilité : $\dfrac{5}{364}$ \\
	Probabilité avec la première rouge : $\dfrac{5}{182}$. \\
	De même, la probabilité d'obtenir un tirage tricolore avec la première boule bleue vaut $\dfrac{5}{182}$, et $\dfrac{5}{182}$ avec la première boule verte. \\
	Donc la probabilité d'obtenir un tirage tricolore est (événements incompatibles) : $\dfrac{15}{182}$.
	
	Les événements "obtenir un tirage tricolore ou unicolore" et "obtenir un tirage bicolore" sont un système complet d'événements, donc la probabilité d'obtenir un 
	tirage bicolore vaut $1-\dfrac{31}{364}-{15}{182} = \dfrac{303}{364}$
	
	\item On effectue maintenant trois tirages successifs avec remise. Répondre aux mêmes questions que dans le premier cas.
	
	\item On effectue trois tirages successifs sans remise. Répondre aux mêmes questions que dans le premier cas. \\
	Quelle est la probabilité que la première boule bleue tirée le soit au troisième tirage ? 
	
\end{enumerate}

\end{exemple}

\subsection{Conditionnement et indépendance}

Il s'agit là d'une notion centrale en probabilités. Essayons de justifier de façon intuitive les définitions qui vont suivre. Considérons une expérience aléatoire, et 
un événement $A$ liée à cette expérience aléatoire. Supposons qu'on sache qu'un certain événement $B$ est réalisé. On a une information supplémentaire, qui va a 
priori modifier les chances de réalisation de $A$, puisqu'elle modifie l'univers qu'on considère. Si on considère encore une fois l'approche par les fréquences, on 
imagine qu'on répète l'expérience aléatoire $n$ fois. On va cette fois compter combien de fois $A$ s'est réalisé lorsque $B$ s'est réalisé. Sur les $n$ répétitions, 
$B$ s'est réalisé $nf_n(B)$ fois, et lorsque $B$ a eu lieu, $A$ s'est aussi réalisé autant de fois que $A \cap B$, c'est-à-dire $nf_n(A \cap B)$ fois. La fréquence de 
réalisation de $A$ parmi les fois où $B$ s'est réalisé est donc :
\begin{center}
$\dfrac{nf_n(A \cap B)}{nf_n(B)} = \dfrac{f_n(A\cap B)}{f_n(B)}$
\end{center}
quantité qui devrait tendre vers $\dfrac{\p(A \cap B)}{\p(B)}$, c'est ce qu'on va appeler la \Strong{probabilité conditionnelle de $A$ sachant $B$}. On dira que $A$ 
est \Strong{indépendant} de $B$ si la réalisation de $B$ n'influe pas sur les chances de réalisation de $A$, c'est-à-dire si la probabilité conditionnelle de $A$ 
sachant $B$ est égale à la probabilité de $A$, ce qui donne $\p(A) = \dfrac{\p(A \cap B)}{\p(B)}$, ou encore (c'est une condition symétrique en $A$ et $B$) si :
\begin{center}
$\p(A \cap B) = \p(A) \p(B)$
\end{center}

\subsubsection{Indépendance}

\begin{definition}{Indépendance}{}
Soit $(\Omega,\p)$ un espace probabilisé fini.
\begin{enumerate}
	\item Soient $A$ et $B$ deux événements. On dit que $A$ et $B$ sont \Strong{indépendants} lorsque 
	\begin{center}
	$\p(A \cap B) = \p(A) \p(B)$
	\end{center}
	\item (Généralisation) Soient $A_1,\cdots,A_n$ des événements. On dit que $A_1,\cdots,A_n$ sont \Strong{indépendants} (on dit aussi \strong{mutuellement 
	indépendants}) lorsque : \\
	pour toute partie non vide $I$ de $\{1,\cdots,n\}$, on a :
	\begin{center}
	$\displaystyle \p\left(\bigcap_{\ell \in I} A_\ell\right) = \prod_{\ell \in I} \p(A_\ell)$
	\end{center}
\end{enumerate}
\end{definition}
	
\end{document}
