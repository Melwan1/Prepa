\documentclass[12pt,a4paper]{report}

\input{00 - preambule}

\begin{document}

\newcommand{\p}{\mathbb{P}}

\section*{Introduction}

La théorie des probabilités a pour objet la modélisation mathématique du hasard, des expériences aléatoires. \\
Une expérience aléatoire est une expérience qui a plusieurs résultats possibles (on dit aussi issues) qu'on ne peut prévoir avec certitude, mais qui présente (c'est 
crucial) une régularité statistique sur le long terme. Il est postulé ici notamment la possibilité de répéter l'expérience un grand nombre de fois, dans des 
conditions identiques (dans l'idéal), de façon indépendante (les différentes répétitions n'ont aucune influence les unes sur les autres). \\
On prend un exemple. Une des expériences aléatoires les plus simples est le jeu de pile ou face : lorsqu'on jette une pièce de monnaie et qu'on regarde quel côté de 
la pièce apparaît, il n'y a que deux issues possibles (pile ou face), et on ne peut prévoir avec certitude quel côté de la pièce apparaît avant de l'avoir lancée. Si 
on jette la même pièce un grand nombre de fois, il semble que la proportion du nombre de piles parmi le nombre total se rapproche d'un nombre fixe (0.5 en général si 
la pièce est équilibrée, un autre nombre sinon), ce qui conduit à définir un nombre qui mesure le degré de vraisemblance d'apparition de pile pour un lancer donné 
(c'est ce qu'on appellera la probabilité d'apparition de pile). Le fait que le hasard fonctionne ainsi résulte de l'expérience (vous pourriez chacun jeter 500 fois 
une pièce de monnaie et consigner combien de fois vous avez obtenu pile dans la série de lancers ; si on fait la moyenne des 47 proportions obtenues, on ne sera pas 
très loin de 0.5...) \\
La modélisation mathématique des phénomènes aléatoires comporte trois ingrédients principaux : 
\begin{enumerate}
	\item L'espace d'états, ou univers, noté traditionnellement $\Omega$ ; c'est l'ensemble de toutes les issues possibles de notre expérience aléatoire. Prenons quelques exemples : 
	\begin{itemize}
		\item Un jeu de pile ou face aura pour univers l'ensemble $\Omega = \{P,F\}$, ou $\Omega = \{0,1\}$. L'expérience aléatoire qui consiste à jeter $n$ fois une 
		pièce, et à collecter les résultats des $n$ lancers se modélise en prenant pour univers $\Omega = \{P,F\}^n$. Un résultat est une suite $\omega = (\omega_1,\cdots,\omega_n)$ d'éléments de $\{P,F\}$.
		\item On modélise l'expérience aléatoire qui consiste à lancer deux dés en prenant pour univers l'ensemble $\Omega = \{1,2,3,4,5,6\}^2$.
		\item L'expérience aléatoire qui consiste à tirer avec remise $n$ boules d'une urne qui contient $N$ boules distinctes (numérotées de $1$ à $N$) aura pour 
		univers $\Omega = \{1,\cdots,N\}$
		\item L'expérience aléatoire qui consiste à tirer en succession et sans remise $n$ boules d'une urne qui contient $N$ boules distinctes (numérotées de $1$ à 
		$N$) aura pour univers l'ensemble des $n$-arrangements d'éléments de $\{1,\cdots,N\}$
		\item L'expérience aléatoire qui consiste à tirer une poignée de $n$ boules dans une urne qui en contient $N$ numérotées de $1$ à $N$ aura pour univers 
		naturel l'ensemble des parties à $n$ éléments de l'ensemble $\{1,\cdots,N\}$ 
		\item L'expérience aléatoire consistant à mesurer la durée de vie d'une ampoule électrique a pour univers $\Omega = \R_+$
	\end{itemize}
	
	Cette année, on s'occupera uniquement du cas où l'ensemble $\Omega$ est fini (cela simplifie beaucoup la théorie mais permet quand même d'en introduire tout le vocabulaire et pas mal d'aspects).
	
	\item Les événements. Un événement est une propriété, vérifiée ou non une fois l'expérience aléatoire réalisée. Par exemple, si on jette deux dés, on peut 
	s'intéresser à l'événement : "la somme des résultats obtenus est un nombre inférieur ou égal à 4". Mathématiquement, un événement sera modélisé par l'ensemble des 
	issues qui le réalisent, c'est donc une partie de l'univers $\Omega$. L'événement de notre exemple est ainsi modélisé par l'ensemble 
	\begin{center}
	$\{(1,1),(1,2),(2,1),(1,3),(3,1),(2,2)\}$
	\end{center}
	Lorsque $\Omega$ est fini, l'ensemble des événements est l'ensemble $P(\Omega)$ des parties de $\Omega$. Il y a un langage propre à la théorie :
	\begin{itemize}
		\item Les événements $\{\omega\}$ (singletons) s'appellent les événements élémentaires.
		\item Si $A$ est un événement, et si l'expérience aléatoire a donné l'issue $\omega$, la traduction de "l'événement $A$ est réalisé" est : $\omega \in A$. 
		\item L'univers $\Omega$ s'appellent l'événement certain, $\varnothing$ est l'événement impossible.
		\item Si $A$ et $B$ sont deux événements, $A \cup B$ est l'événement "$A$ ou $B$", $A \cap B$ est l'événement "$A$ et $B$", et le complémentaire de $A$, noté $\overline{A}$ ou $A^c$ s'appelle l'événement contraire de $A$. Les événements $A$ et $B$ sont incompatibles lorsque $A \cap B = \varnothing$. On dit que $A$ implique $B$ lorsque $A \subset B$.
	\end{itemize}
	
	\item La probabilité $\p$ : à chaque événement $A$ est attaché un nombre $\p(A)$, élément de $[0,1]$, qui mesure le degré de vraisemblance de $A$ (ce nombre est 
	d'autant plus proche de $1$ que les chances que $A$ se produise sont élevées). \\
	
	Reprenons notre approche fréquentielle : répétons l'expérience aléatoire $n$ fois, on note $f_n(A)$ la fréquence de réalisation de l'événement $A$ (c'est le 
	quotient du nombre de fois où $A$ s'est produit par $n$, nombre total de réalisations de l'expérience). On prend alors :
	\begin{center}
	$\p(A) = \underset{n \to +\infty}{\lim} f_n(A)$
	\end{center}
	en postulant l'existence de cette limite. D'après les propriétés des fréquences, on aura alors $\p(\Omega) = 1$ et $\p(A \cup B) = \p(A)+\p(B)$ lorsque $A$ et $B$ 
	sont disjoints. C'est ce qui va nous conduire à la définition rigoureuse d'une probabilité. Le postulat de régularité statistique ne sert qu'à justifier les 
	définitions mathématiques qui vont suivre. Un des aspects très satisfaisant de la théorie est qu'en retour on peut démontrer cette régularité statistique (ce sont 
	les résultats connus sous le nom de loi des grands nombres).
\end{enumerate}

Il y a aussi un quatrième ingrédient, dont nous reparlerons plus tard : les variables aléatoires.

\newpage

\section{Probabilités sur un univers fini}

\subsection{Espaces probabilisés}

\begin{definition}{Probabilité}{}
Soit $\Omega$ un ensemble (univers) fini. On appelle \Strong{probabilité} sur $\Omega$ toute application $\p$ de $P(\Omega)$ dans $[0,1]$ telle que :
\begin{enumerate}
\item $\p(\Omega) = 1$
\item Si $A$ et $B$ sont deux événements incompatibles, $\p(A \cup B) = \p(A) + p(B)$ (additivité)
\end{enumerate}
\end{definition}

\begin{definition}{Espace probabilisé}{}
On appelle \Strong{espace probabilisé fini} tout couple $(\Omega,\p)$ où $\Omega$ est un univers fini et $\p$ une probabilité sur $\Omega$.
\end{definition}

\begin{remarque}{}
Il y a un vocabulaire attaché à la probabilité, un peu artificiel quand on a affaire à des ensembles finis, mais qu'on donne quand même. \\
Soit $(\Omega,\p)$ un espace probabilisé fini. \\
On dit qu'un événement $A$ est \Strong{négligeable} lorsque $\p(A) = 0$ et \Strong{quasi certain} si $\p(A) = 1$. \\
Une propriété sur $\Omega$ est vraie \Strong{presque sûrement} si l'ensemble des points $\omega$ où la propriété est fausse est négligeable. \\

On peut se poser la question de l'existence dans le cas fini d'événements négligeables autres que l'événement impossible. En effet, la modélisation conduit en général
à attribuer à chaque événement élémentaire une probabilité strictement positive, mais rien n'empêche d'ajouter artificiellement des issues de probabilité nulle. Dans 
le cas d'ensembles infinis (non dénombrables), la situation est bien différente. Par exemple, si on modélise un jeu de pile ou face infini (c'est un idéal 
mathématique, évidemment), on est amené à considérer l'ensemble non dénombrable $\Omega = \{0,1\}^\N$ (ensemble des suites infinies d'éléments de $\{0,1\}$). On 
démontre qu'on peut munir $\Omega$ d'une probabilité $\p$ conforme à notre intuition (par exemple, la probabilité d'obtenir "pile" à un lancer donné est de $\dfrac{1}{2}$, 
la probabilité que les $n$ premiers lancers aient des valeurs données est $\dfrac{1}{2^n}$). Alors on montre facilement que la probabilité de chaque événement 
élémentaire est nulle, de même que celle d'obtenir "pile" tous les trois lancers. Il y a bien dans ce cas des événements négligeables qui ne sont pas l'événement 
impossible.

\end{remarque}

\pagebreak

Donnons tout de suite les principales propriétés des probabilités :

\begin{proposition}{Propriétés principales des probabilités}{}

Soit $(\Omega,\p)$ un espace probabilisé fini, $A$ et $B$ deux événements.
\begin{enumerate}
	\item $\p(\varnothing) = 0$
	\item $\p(\overline{A}) = 1- \p(A)$.
	\item Si $A \subset B$, alors $\p(A) \le \p(B)$ (on dit que $\p$ est \strong{croissante}). \\
	Plus précisément, on a $\p(B \setminus A) = \p(B) - \p(A)$ lorsque $A \subset B$.
	\item $\p(A \cup B) = \p(A) + \p(B) - \p(A \cap B)$
	\item Si $A_1,\cdots,A_n$ sont des événements deux à deux incompatibles, alors (additivité finie) :
	\begin{center}
	$\displaystyle \p \left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n \p(A_k)$
	\end{center}
	
	\item Si $A_1,\cdots,A_n$ sont des événements quelconques, alors (inégalité de Boole) :
	\begin{center}
	$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) \le \sum_{k=1}^N \P(A_k)$
	\end{center}
\end{enumerate}

\end{proposition}

\begin{demo}{}
Soient $A$ et $B$ deux événements tels que $A \subset B$. Alors $B$ est réunion disjointe de $A$ et de $B \setminus A$, donc 
\begin{center}
$\p(B) = \p(A \cup (B \setminus A)) = \p(A)+\underbrace{\p(B \setminus A)}_{\ge 0}$,
\end{center}

et ceci donne les trois premières assertions (prendre $A = B = \varnothing$ pour la première, $B = \Omega$ pour la deuxième). \\
À présent, si $A$ et $B$ sont deux événements quelconques, on observe que $A \cup B$ est réunion disjointe de $A$ et de $B \setminus (A \cap B)$ \footnotemark, d'où
\begin{center}
$\p(A \cup B) = \p(A) + \p(B \setminus (A \cap B)) = \p(A) + \p(B) - \p(A \cap B)$
\end{center}

Les deux dernières assertions se prouvent facilement par récurrence.
\end{demo}

\footnotetext{Faire un dessin pour le voir.}

\begin{definition}{Système complet d'événements}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A_1,\cdots,A_n$ des événements. \\
On dit que $(A_1,\cdots,A_n)$ est un \Strong{système complet d'événements} si les $A_i$ sont deux à deux incompatibles et si la réunion des $A_i$ est $\Omega$.
\end{definition}

\begin{remarque}{}
Si $(A_1,\cdots,A_n)$ est un système complet d'événements, on a par additivité finie :
\begin{center}
$1 = \p(\Omega) = \displaystyle \sum_{k=1}^n \p(A_k)$
\end{center}
\end{remarque}

\begin{exemple}{}
Pour tout événement $A$ d'un espace probabilisé fini $(\Omega,\p)$, $(A, \overline{A})$ est un système complet d'événements.\\ 
De même, $({\omega})_{\omega \in \Omega}$ est aussi un système complet d'événements.
\end{exemple}

\begin{proposition}{}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $(A_1,\cdots,A_n)$ un système complet d'événements. Alors, pour tout événement $B$, on a :
\begin{center}
$\p(B) = \displaystyle \sum_{k=1}^n \p(B \cap A_k)$
\end{center}
\end{proposition}

\begin{demo}{}
Soit $B$ un événement. On a :
\begin{center}
$B = B \cap \Omega = B \cap \displaystyle \bigcup_{k=1}^n A_k = \bigcup_{k=1}^n (B \cap A_k)$
\end{center}

et les divers ensembles $B \cap A_1,\cdots,B\cap A_n$ sont deux à deux disjoints, d'où le résultat par additivité finie.
\end{demo}

\begin{exemple}[Exercice 1]{}
La proposition précédente reste vraie si on suppose seulement que les $A_i$ sont deux à deux incompatibles et que leur réunion est un événement quasi-certain.
\end{exemple}

\begin{exemple}[Exercice 2]{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A$ et $B$ deux événements tels que $\p(A) = \dfrac{3}{4}$ et $\p(B) = \dfrac{1}{3}$. \\
Prouver que $\dfrac{1}{12} \le \p(A \cap B) \le \dfrac{1}{3}$. \\

Preuve : on a déjà $\p(A \cap B) = \p(A) + \p(B) - \underbrace{\p(A \cup B)}_{\text{positif et inférieur ou égal à 1}} \ge \dfrac{3}{4}+\dfrac{1}{3}-1 = \dfrac{1}{12}$. \\

De plus, l'événement $A \cap B$ implique l'événement $B$, donc $\p(A \cap B) \le \p(B) = \dfrac{1}{3}$.

\end{exemple}

\begin{exemple}[Exercice 3]{}
Soit $\Omega,\p)$ un espace probabilisé fini, $A_1,\cdots,A_n$ des événements (avec $n \ge 2$). \\
Prouver que
\begin{center}
$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) \ge \sum_{k=1}^n \p(A_k) - \sum_{1 \le k < \ell \le n} \p(A_k \cap A_\ell)$
\end{center}
\end{exemple}

\begin{exemple}[Exercice 4]{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A,B,C$ des événements. Prouver que
\begin{center}
$\p(A \cup B \cup C) = \p(A) + \p(B) + \p(C) - \p(A \cap B) - \p(B \cap C) - \p(A \cap C) + \p(A \cap B \cap C)$
\end{center}
\end{exemple}

Le résultat de l'exercice suivant n'est pas officiellement au programme, mais il est utile, c'est conseillé de le retenir : 

\begin{exemple}[Exercice 5]{Formule de Poincaré}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A_1,\cdots,A_n$ des événements (avec $n \ge 2$). \\
Prouver que :
\begin{center}
$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n (-1)^{k-1} \left(\sum_{1 \le i_1 < \cdots < i_k \le n} \p(A_{i_1} \cap \cdots A_{i_n})\right)$
\end{center}

La somme intérieure porte sur les suites strictement croissantes de $k$ entiers de $\{1,\cdots,n\}$. L'ensemble de ces suites est en bijection avec l'ensemble des 
parties à $k$ éléments de $\{1,\cdots,n\}$ (il n'y a qu'une seule façon de classer par ordre croissant les éléments d'une partie de $\{1,\cdots,n\}$). La somme 
intérieure est donc la somme des probabilités de toutes les intersections possibles de $k$ ensembles parmi $A_1,\cdots,A_n$, elle comporte $\begin{pmatrix} n \\ k\end{pmatrix}$ termes. 
Le premier terme de la somme (obtenu pour $k = 1$) est la somme des probabilités des ensembles $A_1,\cdots,A_n$, affectée d'un signe $+$. Il y a ensuite alternance de 
signes entre deux termes consécutifs. Le dernier terme est $(-1)^{n-1}\p(A_1 \cap \cdots \cap A_n)$. \\

On a l'écriture alternative suivante (en notant, pour $k \in \{1,\cdots,n\}$, $\mathcal{P}_k(n)$ l'ensemble des parties à $k$ éléments de l'ensemble $\{1,\cdots,n\}$) :
\begin{center}
$\displaystyle \p\left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n (-1)^{k-1} \left(\sum_{I \in \mathcal{P}_k(n)} \p\left(\bigcap_{\ell \in I}\right)\right)$
\end{center}

Indice : par récurrence.

\end{exemple}

\begin{remarque}[Petite histoire]{}
Donnons-nous dans un premier temps un ensemble fini $\Omega$.
\begin{itemize}
	\item Soit $\p$ une probabilité sur $\Omega$. Si $A$ est un événement, alors $A$ est réunion disjointe des singletons formés d'un élément de $A$, on a donc, par 
	additivité finie : 
	\begin{center}
	$\p(A) = \displaystyle \sum_{\omega \in A} \p(\{\omega\})$
	\end{center}
	
	On voit donc que $\p$ est entièrement déterminée par sa valeur sur les événements élémentaires. \\
	
	De plus, pour chaque élément $\omega$ de $\Omega$, on a $\p(\{\omega\}) \ge 0$ et $1 = \p(\Omega) = \displaystyle \sum_{\omega \in \Omega} \p(\{\omega\})$.
	
	\item Réciproquement, si on se donne une famille $(p_\omega)_{\omega \in \Omega}$ de nombres réels positifs ou nuls, indexée par $\Omega$, de somme 1, et si on pose, pour $A \in \mathcal{P}(\Omega)$,
	\begin{center}
	$\p(A) = \displaystyle \sum_{\omega \in A} p_\omega$
	\end{center}
	on vérifie sans difficulté aucune qu'on définit bien de cette manière une probabilité sur l'ensemble fini $\Omega$ (exercice).
\end{itemize}
\end{remarque}

Résumons :

\begin{theoreme}{}{}
Se donner une probabilité sur l'ensemble fini $\Omega$ revient à se donner une famille $(p_\omega)_{\omega \in \Omega}$ de nombres réels positifs ou nuls de somme 1. \\
Plus précisément, si on dispose d'une telle famille, il y a une et une seule probabilité $\p$ sur $\Omega$ telle que $\p(\{\omega\}) = p_\omega$ pour tout élément $\omega$ de $\Omega$.
\end{theoreme}

Examinons à présent une situation courante, celle où toutes les issues possibles ont même probabilité : 

\begin{theoreme}{Probabilité uniforme}{}
Soit $\Omega$ un ensemble fini. Il existe une et une seule probabilité $\p$ sur $\Omega$, appelée \Strong{probabilité uniforme}, qui a la même valeur sur tous les 
singletons. \\
On a, pour tout élément $\omega$ de $\Omega$, et pour tout événement $A$ :
\begin{center}
$\p(\{\omega\}) = \dfrac{1}{\text{Card } \Omega}$ et $\p(A) = \dfrac{\text{Card } A}{\text{Card } \Omega}$
\end{center}
\end{theoreme}

\begin{demo}{}
Si $\p$ existe, on doit avoir, en notant $p$ la valeur commune de $\p$ sur les singletons,
\begin{center}
$1 = \p(\Omega) = \displaystyle \sum_{\omega \in \Omega} \p(\{\omega\}) = \sum_{\omega \in \Omega} p = p \text{Card } \Omega$
\end{center}
Donc $p = \dfrac{1}{\text{Card } \Omega}$. \\

Si maintenant on pose, pour $\omega \in \Omega$, $p_\omega = \dfrac{1}{\text{Card } \Omega}$, on a là une famille de réels positifs de somme 1, il existe donc une 
unique probabilité $\p$ sur $\Omega$ telle que
\begin{center}
$\forall \omega \in \Omega, \p(\{\omega\}) = \dfrac{1}{\text{Card} \Omega}$
\end{center}
et on a bien, pour tout événement $A$,
\begin{center}
$\p(A) = \displaystyle \sum_{\omega \in A} \p(\{\omega\}) = \sum_{\omega \in A} \dfrac{1}{\text{Card } \Omega} = \dfrac{\text{Card } A}{\text{Card } \Omega}$
\end{center}
\end{demo}

\begin{remarque}{}
Chaque fois qu'un énoncé fait référence à des tirages ou des choix "au hasard", à des dés "équitables, ou équilibrés, ou non truqués", à des pièces "équilibrées, ou 
non truquées" (pour les jeux de pile ou face), à des boules ou des jetons "indiscernables" (pour des énoncés à bases de tirages dans des urnes), c'est qu'on a affaire 
à une situation d'équiprobabilité, et on munira donc l'univers correspondant de la probabilité uniforme. \\

Le terme "tirage au hasard" n'est pas très bien choisi, le hasard n'est pas toujours synonyme d'équiprobabilité. Par exemple, si l'expérience aléatoire consiste à 
jeter deux dés et à noter la somme des deux résultats obtenus (l'univers est donc l'ensemble des entiers compris entre 2 et 12), il est clair que qu'on a pas affaire 
à une situation d'équiprobabilité, bien que le "hasard" soit toujours à l'œuvre.
\end{remarque}

\begin{remarque}{}
Dans le cas de la probabilité uniforme, la formule $\p(A) = \dfrac{\text{Card } A}{\text{Card } \Omega}$ se lit quelquefois "nombre de cas favorables sur nombre de 
cas possibles" (un cas favorable est une issue qui réalise l'événement $A$). Dans cette situation (très souvent rencontrée), calculer une probabilité, c'est faire du 
dénombrement.
\end{remarque}

\begin{remarque}{}
Un grand nombre d'énoncés aiment à contextualiser la situation : on parle de lancer de dés, de jets de pièces, de tirages dans des urnes. M. Sellès est enclin à 
éviter ce genre d'énoncé, et rester dans le domaine mathématique pur et dur, mais il faut quand même vous préparer à les affronter. Dans ce cas là, c'est à vous de 
préciser quel univers vous adoptez pour modéliser la situation, et aussi quelle probabilité vous considérez sur cet univers. Revenons sur les modèles à base de 
tirages dans des urnes, pour les trois cas les plus simples :
\begin{enumerate}
	\item Si on effectue $n$ tirages avec remise (chaque tirage a lieu en succession, et on remet la boule tirée dans l'urne après chaque tirage) dans une urne qui 
	contient $N$ boules, on prend en général comme univers $\Omega = \{1,\cdots,N\}^n$ et on considère que chaque tirage est équiprobable. Dans ce cas, 
	$\text{Card } \Omega = N^n$. On peut très bien simuler ainsi un jeu de pile ou face (considérer une urne qui contient deux boules).
	\item Si on effectue $n$ tirages successifs sans remise (chaque tirage a lieu en succession, et on garde la boule tirée dans l'urne après chaque tirage) dans une 
	urne qui contient $N$ boules, on prend comme univers $\Omega$ l'ensemble des $n$-uplets d'entiers distincts de $\{1,\cdots,N\}$ (on imagine qu'on a numéroté les 
	$N$ boules), c'est-à-dire les $n$-arrangements de l'ensemble $\{1,\cdots,N\}$, et dans ce cas, $\text{Card}  \Omega = N(N-1) \cdots (N-n+1)$
	\item Si on effectue des tirages simultanés de $n$ boules (on tire des poignées de $n$ boules) dans une urne qui en contient $N$, l'univers $\Omega$ adéquat est 
	en général l'ensemble des parties à $n$ éléments de l'ensemble des $N$ boules, et on a dans ce cas $\text{Card } \Omega = \begin{pmatrix} N \\ n \end{pmatrix}$.
\end{enumerate}
Notons que les fameuses urnes peuvent aussi servir à modéliser des situations non équiprobables (même si les tirages le sont). C'est souvent le cas lorsque l'ensemble 
des boules est divisé en une ou plusieurs sous-populations (caractérisées, en général, par la couleur). Si on vous dit par exemple qu'une urne contient 7 boules, dont 
4 vertes et 3 rouges, et que l'expérience aléatoire consiste à tirer une boule, et à noter sa couleur, on peut prendre comme univers $\Omega = \{V,R\}$ avec $\p(V) = \dfrac{4}{7}$ et $\p(R) = \dfrac{3}{7}$, on a ainsi modélisé un jeu de pile ou face non équitable.
\end{remarque}

\begin{exemple}[Exercice 6]{}
Une urne contient 6 boules rouges, 5 boules vertes et 3 boules bleues.
\begin{enumerate}
	\item On tire simultanément trois boules de l'urne. Quelle est la probabilité d'avoir un tirage unicolore ? Quelle est la probabilité d'avoir un tirage 
	tricolore ? Quelle est la probabilité d'avoir un tirage bicolore ?
	
	$\rightarrow$ Pour avoir un tirage unicolore, il faut soit tirer trois rouges, soit trois bleues, soit trois vertes. La probabilité de tirer trois rouges vaut $\dfrac{6}{14}\dfrac{5}{13}\dfrac{4}{12} = \dfrac{5}{91}$, la probabilité de tirer trois bleues est $\dfrac{3}{14} \dfrac{2}{13} \dfrac{1}{12} = \dfrac{1}{364}$ et celle de tirer trois vertes vaut $\dfrac{5}{14}\dfrac{4}{13}\dfrac{3}{12} = \dfrac{5}{182}$. Donc la probabilité d'obtenir un tirage unicolore vaut $\dfrac{5}{91} + \dfrac{5}{182} + \dfrac{1}{364} = \dfrac{31}{364}$. \\
	
	Tirage tricolore : la première boule n'importe pas, elle est de la couleur qu'on veut.
	Si elle est rouge, alors il faut tirer une verte et une bleue. Si la deuxième est bleue, la troisième doit être verte. probabilité de tout ceci : $\dfrac{6}
{14}\dfrac{3}{13}\dfrac{5}{12} = \dfrac{5}{364}$. \\
	Si la deuxième est verte, la troisième est bleue. Probabilité : $\dfrac{5}{364}$ \\
	Probabilité avec la première rouge : $\dfrac{5}{182}$. \\
	De même, la probabilité d'obtenir un tirage tricolore avec la première boule bleue vaut $\dfrac{5}{182}$, et $\dfrac{5}{182}$ avec la première boule verte. \\
	Donc la probabilité d'obtenir un tirage tricolore est (événements incompatibles) : $\dfrac{15}{182}$.
	
	Les événements "obtenir un tirage tricolore ou unicolore" et "obtenir un tirage bicolore" sont un système complet d'événements, donc la probabilité d'obtenir un 
	tirage bicolore vaut $1-\dfrac{31}{364}-{15}{182} = \dfrac{303}{364}$
	
	\item On effectue maintenant trois tirages successifs avec remise. Répondre aux mêmes questions que dans le premier cas.
	
	\item On effectue trois tirages successifs sans remise. Répondre aux mêmes questions que dans le premier cas. \\
	Quelle est la probabilité que la première boule bleue tirée le soit au troisième tirage ? 
	
\end{enumerate}

\end{exemple}

\subsection{Conditionnement et indépendance}

Il s'agit là d'une notion centrale en probabilités. Essayons de justifier de façon intuitive les définitions qui vont suivre. Considérons une expérience aléatoire, et 
un événement $A$ liée à cette expérience aléatoire. Supposons qu'on sache qu'un certain événement $B$ est réalisé. On a une information supplémentaire, qui va a 
priori modifier les chances de réalisation de $A$, puisqu'elle modifie l'univers qu'on considère. Si on considère encore une fois l'approche par les fréquences, on 
imagine qu'on répète l'expérience aléatoire $n$ fois. On va cette fois compter combien de fois $A$ s'est réalisé lorsque $B$ s'est réalisé. Sur les $n$ répétitions, 
$B$ s'est réalisé $nf_n(B)$ fois, et lorsque $B$ a eu lieu, $A$ s'est aussi réalisé autant de fois que $A \cap B$, c'est-à-dire $nf_n(A \cap B)$ fois. La fréquence de 
réalisation de $A$ parmi les fois où $B$ s'est réalisé est donc :
\begin{center}
$\dfrac{nf_n(A \cap B)}{nf_n(B)} = \dfrac{f_n(A\cap B)}{f_n(B)}$
\end{center}
quantité qui devrait tendre vers $\dfrac{\p(A \cap B)}{\p(B)}$, c'est ce qu'on va appeler la \Strong{probabilité conditionnelle de $A$ sachant $B$}. On dira que $A$ 
est \Strong{indépendant} de $B$ si la réalisation de $B$ n'influe pas sur les chances de réalisation de $A$, c'est-à-dire si la probabilité conditionnelle de $A$ 
sachant $B$ est égale à la probabilité de $A$, ce qui donne $\p(A) = \dfrac{\p(A \cap B)}{\p(B)}$, ou encore (c'est une condition symétrique en $A$ et $B$) si :
\begin{center}
$\p(A \cap B) = \p(A) \p(B)$
\end{center}

\subsubsection{Indépendance}

\begin{definition}{Indépendance}{}
Soit $(\Omega,\p)$ un espace probabilisé fini.
\begin{enumerate}
	\item Soient $A$ et $B$ deux événements. On dit que $A$ et $B$ sont \Strong{indépendants} lorsque 
	\begin{center}
	$\p(A \cap B) = \p(A) \p(B)$
	\end{center}
	\item (Généralisation) Soient $A_1,\cdots,A_n$ des événements. On dit que $A_1,\cdots,A_n$ sont \Strong{indépendants} (on dit aussi \strong{mutuellement 
	indépendants}) lorsque : \\
	pour toute partie non vide $I$ de $\{1,\cdots,n\}$, on a :
	\begin{center}
	$\displaystyle \p\left(\bigcap_{\ell \in I} A_\ell\right) = \prod_{\ell \in I} \p(A_\ell)$
	\end{center}
\end{enumerate}
\end{definition}

\begin{remarque}{}
La notion d'indépendance peut ne pas être très intuitive. Pour montrer que deux événements sont indépendants, il faut faire un calcul de probabilité, l'argument ne peut pas être "on voit bien que", notamment dans les énoncés contextualisés. Le mot "indépendant" a ici une signification mathématique précise. Prenons quelques exemples qui vous convaincront, on l'espère :
\begin{enumerate}
	\item On joue à pile ou face, on effectue deux lancers consécutifs, on note $p$ la probabilité d'apparition de pile à chaque lancer (c'est un réel compris entre 0 et 1). On modélise cette expérience aléatoire par l'univers $\Omega = \{P,F\}^2$, muni de la probabilité $\p$ définie par :
	\begin{center}
		$\P(\{(P,P)\}) = p^2, \p(\{(F,F)\}) = (1-p)^2, \p(\{(F,P)\}) = \p(\{(P,F)\}) = p(1-p)$.
	\end{center}
	
	Considérons $A = \{(P,F),(F,P)\}$ et $B = \{(P,P),(P,F)\}$. \\
	On a tout de suite $\p(A) = 2p(1-p)$ et $\p(B) = p^2+p(1-p) = p$, tandis que $\p(A \cap B) = p(1-p)$. \\
	
	On voit donc que $A$ et $B$ sont indépendants si et seulement si
	\begin{center}
	$p(1-p) = 2p^2(1-p)$
	\end{center}
	ce qui ne laisse que les solutions $p = 0$, $p = 1$ et $p = \dfrac{1}{2}$. \\
	En particulier, dans le cas d'un jeu équilibré ($p = 1/2$), les événements $A$ et $B$ sont indépendants, alors qu'il ne le sont pour aucune valeur non triviale de $p$ (et pourtant, ce sont les mêmes événements). 
	
	\item On considère l'ensemble des familles de trois enfants (du point de vue de la distribution des sexes). En notant $f$ pour fille, $g$ pour garçon, on a 8 possibilités pour les familles de trois enfants (on les range du plus vieux au plus jeune), qu'on va considérer comme étant équiprobables (ce n'est peut-être pas là la bonne modélisation). Autrement dit, on considère l'ensemble $\Omega = \{f,g\}^3$, muni de la probabilité uniforme. Un triplet tel que $(f,g,g)$ indique que le premier enfant est une fille, suivie de deux garçons. Chaque triplet a la probabilité $1/8$. \\
	
	Soit $A$ l'événement "la famille est mixte" (c'est-à-dire présente des enfants des deux sexes), et $B$ l'événement "la famille a au plus un garçon". \\
	Le calcul des probabilités donne $\p(A) = \dfrac{3}{4}$, $\p(B) = \dfrac{1}{2}$, et $\p(A \cap B) = \dfrac{3}{8}$, donc $A$ et $B$ sont indépendants. \\
	
	Si on considère "les mêmes" événements pour des familles de $4$ enfants, ils ne sont plus indépendants (exercice). Ils ne le sont pas non plus pour les familles de deux enfants.
\end{enumerate}
\end{remarque}

\begin{remarque}{}
Dans le cas de $n$ événements, avec $n \ge 3$, il y a en fait $2^n-n-1$ conditions à vérifier (la relation à vérifier étant triviale pour les parties $I$ de $\{1,\cdots,n\}$ de cardinal 1). Par exemple lorsque $n = 3$, les événements $A$, $B$ et $C$ sont indépendants si et seulement si :
\begin{center}
$\p(A \cap B) = \p(A) \p(B)$, $\p(A \cap C) = \p(A) \p(C)$ et $\p(B \cap C) = \p(B) \p(C)$ \\
$\p(A \cap B \cap C) = \p(A)\p(B) \p(C)$
\end{center}
\end{remarque}

L'indépendance de trois événements implique donc l'indépendance deux à deux. On pourrait penser que la réciproque est vraie, mais ce n'est pas le cas. De même, la deuxième condition n'implique pas l'indépendance deux à deux. On vous renvoie aux deux exemples suivants.

\begin{exemple}{}
Considérons $\Omega = \{a,b,c,d\}$, muni de la probabilité uniforme. Soient $A = \{a,d\}$, $B = \{b,d\}$ et $C = \{c,d\}$. Alors les événements $A,B,C$ sont deux à deux indépendants, mais on a $\p(A\cap B \cap C) \ne \p(A)\p(B)\p(C)$.
\end{exemple}

\begin{exemple}{}
Soit $\Omega = \{1,\cdots,8\}$, muni de la probabilité uniforme. On prend $A = B = \{1,5,6,7\}$, et $C = \{1,2,3,4\}$. Alors $\p(A \cap B \cap C) = \p(A) \p(B) \p(C)$, mais $A,B$ et $C$ ne sont pas deux à deux indépendants.
\end{exemple}

\begin{exemple}[Exercice 7]{}
Soit $n$ un entier, $n \ge 2$. On modélise un jeu de pile ou face équitable avec $n$ lancers par l'univers $\{0,1\}^n$, muni de la probabilité uniforme. Pour tout entier $i$ compris entre $1$ et $n$, on note $A_i$ l'événement "le $i$-ème lancer à donné pile" (dans notre modèle, $A_i$ est l'ensemble des $\omega = (\omega_1,\cdots,\omega_n)$ tels que $\omega_i = 1$).
\begin{enumerate}
	\item Pour $1 \le i < j \le n$, prouver que $A_i$ et $A_j$ sont indépendants.
	\item Prouver que les événements $(A_1,\cdots,A_n)$ sont indépendants.
	\item Pour $1 \le k \le n$, soit $B_k$ l'événement "on a obtenu $k$ piles exactement parmi les $n$ lancers". Quelle est la probabilité de $B_k$ ?
\end{enumerate}
\end{exemple}

\begin{remarque}{}
L'indépendance d'événements $A_1,\cdots,A_n$ ne dépend évidemment pas de leur ordre d'énumération. \\
Par ailleurs, si $A_1,\cdots,A_n$ sont indépendants, il est tout aussi clair que $A_1,\cdots,A_k$ le sont aussi, pour tout entier $k$ compris entre $1$ et $n$.
\end{remarque}

\begin{proposition}{}{}
Soient $A$ et $B$ deux événements indépendance de l'espace probabilisé $(\Omega, \p)$. \\
Alors les événements $\overline{A}$ et $B$ sont aussi indépendants, de même que $A$ et $\overline{B}$ et $\overline{A}$ et $\overline{B}$.
\end{proposition}

\begin{demo}{}
Il suffit évidemment de montrer que $\overline{A}$ et $B$ sont indépendants. On remarque que
\begin{center}
$B = B \cap \Omega = B \cap (A \cup \overline{A}) = (B \cap A) \cup (B \cap \overline{A})$,
\end{center}
et les événements $B \cap A$ et $B \cap \overline{A}$ sont incompatibles. On a donc 
\begin{center}
$\p(B \cap \overline{A} = \p(B) - \p(B \cap A) = \p(B)-\p(B)\p(A) = \p(B)(1-\p(A)) = \p(B)\p(\overline{A})$. 
\end{center}
\end{demo}

La proposition précédente se généralise ainsi : 
\begin{proposition}{}{}
Soient $A_1,\cdots,A_n$ des événements indépendants de l'espace probabilisé $(\Omega,\p)$. Alors il en est de même des événements $B_1,\cdots,B_n$ où $B_i$ est $A_i$ ou $\overline{A_i}$ pour tout entier $i$ compris entre $1$ et $n$.
\end{proposition}

\begin{demo}{}
Il suffit en fait de voir que les événements $\overline{A_1},A_2,\cdots,A_n$ sont indépendants (voyez-vous pourquoi ?), et pour ceci, il suffit de prouver que si $k$ est un entier compris entre $2$ et $n$, alors
\begin{center}
$\p(\overline{A_1} \cap A_2 \cap \cdots \cap A_k) = \p(\overline{A_1}) \p(A_2) \cdots \p(A_k)$.
\end{center}

Or c'est facile : soit $k$ un entier compris entre $2$ et $n$. On remarque que $A_1$ et $C = A_2 \cap \cdots \cap A_k$ sont indépendants car 
\begin{center}
$\p(A_1 \cap C) = \displaystyle \p\left(\bigcap_{i=1}^k A_i\right) = \prod_{i=1}^k \p(A_i) = \p(A_1)\p(C)$.
\end{center}
par indépendance de $A_1,\cdots,A_n$.

D'après la proposition précédente, $\overline{A}$ et $C$ sont indépendants, ce qui entraîne le résultat.
\end{demo}

\begin{proposition}{}{}
Soient $A_1,\cdots,A_n$ des événements indépendants de l'espace probabilisé $(\Omega,\p)$, et $p$ un entier compris entre $1$ et $n-1$. Alors 
\begin{enumerate}
	\item Les événements $A_1 \cap \cdots \cap A_p$ et $A_{p+1}\cap \cdots A_n$ sont indépendants.
	\item Les événements $A_1 \cup \cdots \cup A_p$ et $A_{p+1}\cup \cdots A_n$ sont indépendants.
	\item Les événements $A_1 \cap \cdots \cap A_p$ et $A_{p+1}\cup \cdots A_n$ sont indépendants.
\end{enumerate}
\end{proposition}

\begin{demo}{}
Montrons la première assertion. \\
Soit $A = A_1 \cap \cdots \cap A_p$ et $B = A_{p+1} \cap \cdots \cap A_n$. \\

Alors $A \cap B = A_1 \cap \cdots \cap A_n$ et par indépendance de $A_1,\cdots,A_n$, on a 
\begin{center}
$\p(A \cap B) = \p(A_1 \cap \cdots \cap A_n) = \displaystyle \prod_{k=1}^n \p(A_k)$
\end{center}

Or, toujours par indépendance de $A_1,\cdots,A_n$, on a 
\begin{center}
$\p(A) = \displaystyle \prod_{k=1}^p \p(A_k)$ et $\p(B) = \displaystyle \prod_{k=p+1}^n \p(A_k)$,
\end{center}
on en déduit bien que
\begin{center}
$\p(A \cap B) = \p(A) \p(B)$.
\end{center}

Pour la deuxième assertion, remarquons que les événements $\overline{A_1}, \cdots, \overline{A_n}$ sont indépendants d'après la proposition précédente. D'après le premier cas, les événements $A = \displaystyle \bigcap_{k=1}^p \overline{A_k}$ et $B = \displaystyle \bigcap_{k=p+1}^n \overline{A_k}$ sont indépendants. Or on a 
\begin{center}
$A =\displaystyle \overline{\bigcup_{k=1}^p A_k}$ et $B = \displaystyle \overline{\bigcup_{k=p+1}^n A_k}$.
\end{center}

Comme $\overline{A}$ et $\overline{B}$ sont indépendants, on a le résultat. \\

Pour la troisième assertion, remarquons que les événements $A_1,\cdots,A_p, \overline{A_{p+1}}, \cdots, \overline{A_n}$ sont indépendants. On en déduit que $A = \bigcap_{k=1}^p A_k$ et $B = \bigcap_{k=1}^p \overline{A_k} = \overline{\bigcup_{k=1}^p A_k}$ sont indépendants d'après le premier cas. On sait alors que $A$ et $\overline{B}$ sont aussi indépendants. 

\end{demo}

\paragraph{Modélisation d'une succession d'épreuves indépendantes}

Imaginons pour commencer qu'on ait modélisé deux expériences aléatoires $\mathcal{E}_1$ et $\mathcal{E}_2$ avec les espaces probabilisés finis $(\Omega_1,\p_1)$ et $(\Omega_2,\p_2)$. On aimerait modéliser la succession des deux expériences, de façon indépendante. Un résultat lié à cette succession est un couple $(\omega_1,\omega_2)$ avec $\omega_1 \in \Omega_1$ et $\omega_2 \in \Omega_2$. \\
On va donc prendre pour univers l'ensemble $\Omega = \Omega_1 \times \Omega_2$. \\
Reste à définir une probabilité $\p$ sur $\Omega$ qui traduise l'indépendance. \\

Ce qu'on veut, c'est que si $A_1$ est un événement lié à l'expérience $\mathcal{E}_1$, $A_2$ un événement lié à $\mathcal{E}_2$, alors $A_1$ et $A_2$ sont indépendants dans la succession de $\mathcal{E}_1$ et $\mathcal{E}_2$. Une petite difficulté se présente ici, puisque si $A_1$ est une partie de $\Omega_1$, ce n'est pas une partie de $\Omega$, on va la remplacer par $A_1 \times \Omega_2$ (il semble logique de considérer que $A_1$ et $A_1 \times \Omega_2$ représentent le même événement). Dans cette optique, on va imposer que $\p(A_1 \times \Omega_2) = \p_1(A_1)$. On imposera de même $\p(\Omega_1 \times A_2) = \p_2(A_2)$ pour toute partie $A_2$ de $\Omega_2$. \\

On veut donc définir une probabilité $\p$ sur $\Omega$ de telle sorte que pour toutes parties $A_1$ et $A_2$ de $\Omega_1$ et $\Omega_2$, on ait d'une part
\begin{center}
$\p(A_1 \times \Omega_2) = \p_1(A_1), \p(\Omega_1 \times A_2) = \p_2(A_2)$,
\end{center}
et d'autre part (puisqu'on veut l'indépendance de $A_1 \times \Omega_2$ et $\Omega_1 \times A_2$), 
\begin{center}
$\p((A_1 \times \Omega_2) \cap (\Omega_1 \times A_2)) = \p(A_1 \times \Omega_2) \p(\Omega_1 \times A_2)$.
\end{center}
or, il est clair que $(A_1 \times \Omega_2) \cap (\Omega_1 \times A_2) = A_1 \times A_2$, on est ainsi conduit à poser, pour $A_1$ partie de $\Omega_1$ et $A_2$ partie de $\Omega_2$, 
\begin{center}
$\p(A_1 \times A_2) = \p_1(A_1) \p_2(A_2)$,
\end{center}
et, en particulier, pour tout $\omega = (\omega_1,\omega_2)\in \Omega$,
\begin{center}
$\p(\{\omega\}) = \p_1(\{\omega_1\}) \p_2(\{\omega_2\}) \underset{\text{def}}{=} p_\omega$
\end{center}

Or il est clair que les nombres $p_\omega$ sont des réels positifs, et de plus
\begin{center}
$\displaystyle \sum_{\omega \in \Omega} p_\omega = \sum_{(\omega_1,\omega_2) \in \Omega_1 \times \Omega_2}  \p_1(\{\omega_1\}) \p_2(\{\omega_2\}) = \underbrace{\left(\sum_{\omega_1 \in \Omega_1}\p_1(\{\omega_1\})\right)}_{=1}\underbrace{\left(\sum_{\omega_2 \in \Omega_2} \p_2(\{\omega_2\})\right)}_{=1} = 1$
\end{center}
Il existe donc bien une probabilité $\p$ sur $\Omega$ telle que $\p(\{\omega\}) = p_\omega$ pour $\omega \in \Omega$, et $\p$ a bien les propriétés attendues. La probabilité $\p$ ainsi définie s'appelle la \Strong{probabilité produit}. \\

On généralise sans problèmes à la modélisation d'une succession indépendante de $n$ expériences aléatoires, modélisées par les espaces probabilisés finis $(\Omega_i,\p_i)$ ($1 \le i \le n$) : il suffit de considérer l'univers $\Omega = \prod_{i=1}^n \Omega_i$ (produit cartésien des ensembles $\Omega_1, \cdots,\Omega_n$), muni du l'unique probabilité $\p$ telle que, quels que soient les éléments $A_i \subset \Omega_i$ ($1 \le i \le n$) : 
\begin{center}
$\p(A_1 \times \cdots \times A_n) = \p_1(A_1) \cdots \p_n(A_n)$.
\end{center}

On peut en particulier modéliser une succession finie de $n$ expériences aléatoires identiques et indépendantes (on parle d'épreuves répétées). Supposons avoir modélisé une expérience aléatoire par un espace probabilisé fini $(\Omega,\p)$. Alors une suite de $n$ épreuves sera modélisée par l'espace probabilisé $(\Omega^n, \mathbb{Q}$, où la probabilité $\mathbb{Q}$ est telle que : quels que soient les événements $A_1, \cdots, A_n$, 
\begin{center}
$\mathbb{Q}(A_1 \times \cdots \times A_n) = \p(A_1) \cdots \p(A_n)$
\end{center}

En particulier, pour tout élément $\omega = (\omega_1,\cdots,\omega_n) \in \Omega^n$, 
\begin{center}
$\mathbb{Q}(\{\omega\}) = \p(\{\omega_1\}) \cdots \p(\{\omega_n\})$
\end{center}

C'est ainsi qu'on modélise un jeu de pile ou face à $n$ lancers. L'expérience que l'on répète (un lancer) est modélisée en général par $\Omega = \{0,1\}$ (où, par exemple, $1$ représente "pile" et $0$ représente "face"), muni de la probabilité $\p$ définie par $\p(\{1\}) = p \in [0,1]$ et $\p(\{0\}) = 1-p = q$. \\
La suite des $n$ lancers indépendante est alors modélisée par l'univers $\{0,1\}^n$, muni de la probabilité $\mathbb{Q}$ définie par
\begin{center}
$\forall \omega = (\omega_1,\cdots,\omega_n) \in \{0,1\}^n, \mathbb{Q}(\{\omega\}) = \displaystyle \prod_{k=1}^n \p(\{\omega_k\}) = p^\ell q^{n-\ell}$
\end{center}
où $\ell$ est le nombre de composantes de $\omega$ qui valent $1$. \\

Dans le cas d'un jeu équitable ($p = q = \dfrac{1}{2}$), on retrouve l'univers $\{0,1\}^n$ muni de la probabilité uniforme. \\

On appellera plus généralement \Strong{épreuve de Bernoulli} toute expérience aléatoire ayant deux issues possibles, baptisées en général "succès" et "échec". Il est clair qu'on peut modéliser une telle expérience par l'univers $\Omega = \{0,1\}$, où $1$ représente (par exemple) le succès, et $0$ l'échec. Une suite de $n$ épreuves de Bernoulli porte le nom de \Strong{schéma de Bernoulli}, et peut se modéliser comme le jeu de pile ou face.

\subsubsection{Probabilité conditionnelle}

\begin{definition}{Probabilité conditionnelle}{}
Soit $(\Omega,\p)$ un espace probabilisé fini, $A$ et $B$ deux événements, avec $\p(B) \ne 0$. \\
On appelle \Strong{probabilité conditionnelle} de $A$ sachant $B$, et on note $\p_B(A)$ (ou parfois $\p(A \mid B)$), le nombre 
\begin{center}
$\p_B(A) = \dfrac{\p(A \cap B)}{\p(B)}$
\end{center}
\end{definition}

On a donc
\begin{center}
$\p(A \cap B) = \p(B) \p_B(A)$.
\end{center}
	
\end{document}
